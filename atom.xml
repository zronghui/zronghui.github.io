<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zronghui的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zronghui.github.io/"/>
  <updated>2020-04-09T02:59:36.000Z</updated>
  <id>https://zronghui.github.io/</id>
  
  <author>
    <name>zronghui</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>tricks-2020-04-2th-week</title>
    <link href="https://zronghui.github.io/tricks/tricks-2020-04-2th-week.html"/>
    <id>https://zronghui.github.io/tricks/tricks-2020-04-2th-week.html</id>
    <published>2020-04-08T01:24:59.000Z</published>
    <updated>2020-04-09T02:59:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="tricks" scheme="https://zronghui.github.io/categories/tricks/"/>
    
    
  </entry>
  
  <entry>
    <title>周赛思路参考</title>
    <link href="https://zronghui.github.io/Leetcode%20weekly%20contest/%E5%91%A8%E8%B5%9B%E6%80%9D%E8%B7%AF%E5%8F%82%E8%80%83.html"/>
    <id>https://zronghui.github.io/Leetcode%20weekly%20contest/%E5%91%A8%E8%B5%9B%E6%80%9D%E8%B7%AF%E5%8F%82%E8%80%83.html</id>
    <published>2020-04-05T10:09:48.000Z</published>
    <updated>2020-04-07T15:01:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><p><a href="https://leetcode.com/contest/">Contest - LeetCode</a></p><p>题解：</p><p><a href="https://www.acwing.com/user/myspace/solution/index/leetcode/21/35/">个人空间 - AcWing</a></p><p><a href="https://space.bilibili.com/97228279">一俩三四五的个人空间 - 哔哩哔哩 ( ゜- ゜)つロ 乾杯~ Bilibili</a></p><p><a href="https://liqiang.io/">格物致知</a></p><p><a href="http://github.tiankonguse.com/index.html">tiankonguse’s 代码世界</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="Leetcode weekly contest" scheme="https://zronghui.github.io/categories/Leetcode-weekly-contest/"/>
    
    
  </entry>
  
  <entry>
    <title>biweekly-contest-23</title>
    <link href="https://zronghui.github.io/Leetcode%20weekly%20contest/biweekly-contest-23.html"/>
    <id>https://zronghui.github.io/Leetcode%20weekly%20contest/biweekly-contest-23.html</id>
    <published>2020-04-05T03:58:36.000Z</published>
    <updated>2020-04-07T15:01:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><ul><li><input checked="" disabled="" type="checkbox"> <a href="https://leetcode.com/contest/biweekly-contest-23/problems/count-largest-group">Count Largest Group</a><strong>3</strong></li><li><input checked="" disabled="" type="checkbox"> <a href="https://leetcode.com/contest/biweekly-contest-23/problems/construct-k-palindrome-strings">Construct K Palindrome Strings</a><strong>5</strong></li><li><input disabled="" type="checkbox"> <a href="https://leetcode.com/contest/biweekly-contest-23/problems/circle-and-rectangle-overlapping">Circle and Rectangle Overlapping</a><strong>5</strong></li><li><input checked="" disabled="" type="checkbox"> <a href="https://leetcode.com/contest/biweekly-contest-23/problems/reducing-dishes">Reducing Dishes</a><strong>6</strong></li></ul><h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">countLargestGroup</span><span class="params">(self, n: int)</span> -&gt; int:</span></span><br><span class="line">        <span class="comment"># &#123;sum: [n1, n2], &#125;</span></span><br><span class="line">        d = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line">            _sum = <span class="number">0</span></span><br><span class="line">            t = i</span><br><span class="line">            <span class="keyword">while</span> t:</span><br><span class="line">                _sum += t%<span class="number">10</span></span><br><span class="line">                t = int(t/<span class="number">10</span>)</span><br><span class="line">            <span class="keyword">if</span> _sum <span class="keyword">not</span> <span class="keyword">in</span> d:</span><br><span class="line">                d[_sum] = [i]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                d[_sum].append(i)</span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        m = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> d.values():</span><br><span class="line">            <span class="keyword">if</span> len(i)==m:</span><br><span class="line">                result += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> len(i) &gt; m:</span><br><span class="line">                result = <span class="number">1</span></span><br><span class="line">                m = len(i)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">canConstruct</span><span class="params">(self, s: str, k: int)</span> -&gt; bool:</span></span><br><span class="line">        <span class="keyword">if</span> len(s)&lt;k:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> len(s)==k:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="comment"># 单数，双数 个数 x, y</span></span><br><span class="line">        <span class="comment"># 前提：len(s)=x+2y&gt;k</span></span><br><span class="line">        <span class="comment"># 要求：x&lt;=k</span></span><br><span class="line">        l = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> s:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> l:</span><br><span class="line">                l.remove(i)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                l.append(i)</span><br><span class="line">        <span class="keyword">if</span> len(l) &lt;= k:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="3"><a href="#3" class="headerlink" title="3"></a>3</h2><p>事后看一两三四五的解法，做出来的</p><p><a href="https://www.bilibili.com/video/BV1Ae411x7fa/?p=1">https://www.bilibili.com/video/BV1Ae411x7fa/?p=1</a></p><p>LeetCode 考的是智商吧</p><img src="/Users/zhangronghui/Library/Application Support/typora-user-images/image-20200405151432618.png" alt="image-20200405151432618" style="zoom:50%;" /><p>求距离时不要用 根号，反之把半径平方即可比较，否则会很慢</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">d</span><span class="params">(self, x1, y1, x2, y2)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> (x1-x2)**<span class="number">2</span>+(y1-y2)**<span class="number">2</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">checkOverlap</span><span class="params">(self, r: int, x: int, y: int, x1: int, y1: int, x2: int, y2: int)</span> -&gt; bool:</span></span><br><span class="line">        <span class="comment"># 圆心在矩形内</span></span><br><span class="line">        <span class="keyword">if</span> x1 &lt;= x &lt;= x2 <span class="keyword">and</span> y1 &lt;= y &lt;= y2:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="comment"># 圆心到上下两边的距离</span></span><br><span class="line">        <span class="keyword">if</span> x1 &lt;= x &lt;= x2 <span class="keyword">and</span> min(abs(y1-y), abs(y2-y))&lt;=r:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="comment"># 圆心到左右两边的距离</span></span><br><span class="line">        <span class="keyword">if</span> y1 &lt;= y &lt;= y2 <span class="keyword">and</span> min(abs(x1-x), abs(x2-x))&lt;=r:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="comment"># # 圆心到四点的距离</span></span><br><span class="line">        <span class="keyword">if</span> min(self.d(x, y, x1, y1), self.d(x, y, x1, y2), self.d(x, y, x2, y1), self.d(x, y, x2, y2)) &lt;= r*r:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><p>另一种思路：</p><p>将矩形扩大后判断圆心是否在里面，接着判断圆心到四个顶点的距离是否不大于 r</p><p>其实这就是上面解法的另一种解释</p><img src="https://i.loli.net/2020/04/05/5DRCiebSaBYI8Gu.png" alt="5DRCiebSaBYI8Gu" style="zoom:50%;" /><h2 id="4"><a href="#4" class="headerlink" title="4"></a>4</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSatisfaction</span><span class="params">(self, satisfaction: List[int])</span> -&gt; int:</span></span><br><span class="line">        <span class="comment"># 1. sort</span></span><br><span class="line">        <span class="comment"># 2. 找到第一个让 sum 为负数的位置, 移动中将 sum 加到 result 中</span></span><br><span class="line">        satisfaction.sort(reverse=<span class="literal">True</span>)</span><br><span class="line">        _sum  = <span class="number">0</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> satisfaction:</span><br><span class="line">            _sum += i</span><br><span class="line">            <span class="keyword">if</span> _sum&lt;<span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            result += _sum</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="Leetcode weekly contest" scheme="https://zronghui.github.io/categories/Leetcode-weekly-contest/"/>
    
    
  </entry>
  
  <entry>
    <title>weekly-contest-183</title>
    <link href="https://zronghui.github.io/Leetcode%20weekly%20contest/weekly-contest-183.html"/>
    <id>https://zronghui.github.io/Leetcode%20weekly%20contest/weekly-contest-183.html</id>
    <published>2020-04-05T03:58:19.000Z</published>
    <updated>2020-04-09T02:59:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><ul><li><input checked="" disabled="" type="checkbox"> <a href="https://leetcode.com/contest/weekly-contest-183/problems/minimum-subsequence-in-non-increasing-order">Minimum Subsequence in Non-Increasing Order</a><strong>4</strong></li><li><input checked="" disabled="" type="checkbox"> <a href="https://leetcode.com/contest/weekly-contest-183/problems/number-of-steps-to-reduce-a-number-in-binary-representation-to-one">Number of Steps to Reduce a Number in Binary Representation to One</a><strong>4</strong></li><li><input disabled="" type="checkbox"> <a href="https://leetcode.com/contest/weekly-contest-183/problems/longest-happy-string">Longest Happy String</a><strong>6</strong></li><li><input disabled="" type="checkbox"> <a href="https://leetcode.com/contest/weekly-contest-183/problems/stone-game-iii">Stone Game III</a><strong>7</strong></li></ul><img src="/Users/zhangronghui/Library/Application Support/typora-user-images/image-20200405120055077.png" alt="image-20200405120055077" style="zoom:50%;" /><h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minSubsequence</span><span class="params">(self, nums: List[int])</span> -&gt; List[int]:</span></span><br><span class="line">        <span class="keyword">if</span> len(nums)&lt;<span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> nums</span><br><span class="line">        nums.sort(reverse=<span class="literal">True</span>)</span><br><span class="line">        _sum = sum(nums)</span><br><span class="line">        t = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, k <span class="keyword">in</span> enumerate(nums):</span><br><span class="line">            t += k</span><br><span class="line">            <span class="keyword">if</span> t&gt;_sum/<span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> nums[:i+<span class="number">1</span>]</span><br></pre></td></tr></table></figure><h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'0'</span> <span class="keyword">not</span> <span class="keyword">in</span> s:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">'1'</span> + len(s)*<span class="string">'0'</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> list(range(len(s)))[::<span class="number">-1</span>]:</span><br><span class="line">            <span class="keyword">if</span> s[i]==<span class="string">'0'</span>:</span><br><span class="line">                <span class="keyword">return</span> s[:i] + <span class="string">'1'</span> + <span class="string">'0'</span> * (len(s)-i<span class="number">-1</span>)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numSteps</span><span class="params">(self, s: str)</span> -&gt; int:</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> len(s)==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> s!=<span class="string">'1'</span>:</span><br><span class="line">            result += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> s[<span class="number">-1</span>]==<span class="string">'0'</span>:</span><br><span class="line">                s = s[:<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                s = self.add(s)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h2 id="3"><a href="#3" class="headerlink" title="3"></a>3</h2><p>(贪心) O((a+b+c)2)O((a+b+c)2)<br>我们交替地往原字符串中插入 a，b 或 c，且保证每一次插入时都不会破坏规则。<br>由于是交替的插入，所以如果出现了某个字符不能插入的情况，则说明无论如何都没有办法插入这么多个该字符。</p><img src="https://i.loli.net/2020/04/05/S3muIil68NCVzWt.png" alt="S3muIil68NCVzWt" style="zoom: 33%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span><span class="params">(self, s, c)</span>:</span></span><br><span class="line">        <span class="comment"># 返回插入 i(a, b, c) 后的 s, isSuccess</span></span><br><span class="line">        <span class="comment"># 长度小于 2 or 第一个字母不同 or 第二位不同 直接放首位</span></span><br><span class="line">        <span class="keyword">if</span> len(s)&lt;<span class="number">2</span> <span class="keyword">or</span> s[<span class="number">0</span>]!=c <span class="keyword">or</span> s[<span class="number">1</span>]!=c:</span><br><span class="line">            <span class="keyword">return</span> c + s, <span class="literal">True</span></span><br><span class="line">        <span class="comment"># last 字母不同 or last-1 字母不同，直接放末位</span></span><br><span class="line">        <span class="keyword">if</span> s[<span class="number">-1</span>]!=c <span class="keyword">or</span> s[<span class="number">-2</span>]!=c:</span><br><span class="line">            <span class="keyword">return</span> s + c, <span class="literal">True</span></span><br><span class="line">        <span class="comment"># now len(s) &gt;= 5  等于 5 的情况：ccbcc</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, len(s)<span class="number">-2</span>):</span><br><span class="line">            <span class="keyword">if</span> s[i<span class="number">-1</span>]==c <span class="keyword">and</span> s[i<span class="number">-2</span>]==c:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> s[i<span class="number">-1</span>]!=c <span class="keyword">and</span> (s[i]!=c <span class="keyword">or</span> s[i+<span class="number">1</span>]!=c):</span><br><span class="line">                <span class="keyword">return</span> s[:i] + c + s[i:], <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> s, <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">longestDiverseString</span><span class="params">(self, a: int, b: int, c: int)</span> -&gt; str:</span></span><br><span class="line">        <span class="comment"># 逐个插入 a b c ，直至插入失败或者插完</span></span><br><span class="line">        s = <span class="string">''</span></span><br><span class="line">        <span class="keyword">while</span> a+b+c:</span><br><span class="line">            <span class="keyword">if</span> a:</span><br><span class="line">                s, ok = self.insert(s, <span class="string">'a'</span>)</span><br><span class="line">                a -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> ok:</span><br><span class="line">                    <span class="keyword">return</span> s</span><br><span class="line">            <span class="keyword">if</span> b:</span><br><span class="line">                s, ok = self.insert(s, <span class="string">'b'</span>)</span><br><span class="line">                b -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> ok:</span><br><span class="line">                    <span class="keyword">return</span> s</span><br><span class="line">            <span class="keyword">if</span> c:</span><br><span class="line">                s, ok = self.insert(s, <span class="string">'c'</span>)</span><br><span class="line">                c -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> ok:</span><br><span class="line">                    <span class="keyword">return</span> s</span><br><span class="line">            print(s)</span><br><span class="line">        <span class="keyword">return</span> s</span><br></pre></td></tr></table></figure><h2 id="4"><a href="#4" class="headerlink" title="4"></a>4</h2><img src="https://i.loli.net/2020/04/08/oQypV49rS5KL32k.png" alt="oQypV49rS5KL32k" style="zoom:50%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">stoneGameIII</span><span class="params">(self, l: List[int])</span> -&gt; str:</span></span><br><span class="line">        dp = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(len(l))]</span><br><span class="line">        dp[<span class="number">-1</span>] = l[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> len(l)&gt;<span class="number">1</span>:</span><br><span class="line">            dp[<span class="number">-2</span>] = max(l[<span class="number">-2</span>]-dp[<span class="number">-1</span>], sum(l[<span class="number">-2</span>:]))</span><br><span class="line">        <span class="keyword">if</span> len(l)&gt;<span class="number">2</span>:</span><br><span class="line">            dp[<span class="number">-3</span>] = max(l[<span class="number">-3</span>]-dp[<span class="number">-2</span>], l[<span class="number">-3</span>]+l[<span class="number">-2</span>]-dp[<span class="number">-1</span>], sum(l[<span class="number">-3</span>:]))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(l)<span class="number">-4</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">            dp[i] = max(l[i]-dp[i+<span class="number">1</span>], l[i]+l[i+<span class="number">1</span>]-dp[i+<span class="number">2</span>], l[i]+l[i+<span class="number">1</span>]+l[i+<span class="number">2</span>]-dp[i+<span class="number">3</span>])</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'Alice'</span> <span class="keyword">if</span> dp[<span class="number">0</span>]&gt;<span class="number">0</span> <span class="keyword">else</span> <span class="string">'Bob'</span> <span class="keyword">if</span> dp[<span class="number">0</span>]&lt;<span class="number">0</span> <span class="keyword">else</span> <span class="string">'Tie'</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="Leetcode weekly contest" scheme="https://zronghui.github.io/categories/Leetcode-weekly-contest/"/>
    
    
  </entry>
  
  <entry>
    <title>信息系统实训-第3次作业</title>
    <link href="https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD-%E7%AC%AC3%E6%AC%A1%E4%BD%9C%E4%B8%9A.html"/>
    <id>https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD-%E7%AC%AC3%E6%AC%A1%E4%BD%9C%E4%B8%9A.html</id>
    <published>2020-04-01T06:48:29.000Z</published>
    <updated>2020-04-01T06:55:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><h2 id="建立index，插入数据"><a href="#建立index，插入数据" class="headerlink" title="建立index，插入数据"></a>建立index，插入数据</h2><h3 id="code"><a href="#code" class="headerlink" title="code"></a>code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> chain</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pretty_errors</span><br><span class="line"><span class="keyword">from</span> elasticsearch <span class="keyword">import</span> Elasticsearch, helpers</span><br><span class="line"></span><br><span class="line">pretty_errors.activate()</span><br><span class="line"></span><br><span class="line">es = Elasticsearch()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立index</span></span><br><span class="line">mapping = &#123;</span><br><span class="line">    <span class="string">'properties'</span>: &#123;</span><br><span class="line">        <span class="string">'book_name'</span>: &#123;</span><br><span class="line">            <span class="string">'type'</span>: <span class="string">'text'</span>,</span><br><span class="line">            <span class="string">'analyzer'</span>: <span class="string">'ik_max_word'</span>,</span><br><span class="line">            <span class="string">'search_analyzer'</span>: <span class="string">'ik_max_word'</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">es.indices.delete(index=<span class="string">'books'</span>, ignore=[<span class="number">400</span>, <span class="number">404</span>])</span><br><span class="line">es.indices.create(index=<span class="string">'books'</span>, ignore=<span class="number">400</span>)</span><br><span class="line">result = es.indices.put_mapping(index=<span class="string">'books'</span>, doc_type=<span class="string">'books'</span>, body=mapping)</span><br><span class="line">print(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量插入数据</span></span><br><span class="line">print(<span class="string">"============== index ================"</span>)</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line">j = <span class="number">0</span></span><br><span class="line">num = <span class="number">0</span></span><br><span class="line">actions = []</span><br><span class="line">max_count = <span class="number">2000</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'shudan1.json'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f1, open(<span class="string">'volmoe1.json'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f2:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> chain(f1, f2):</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            triple_dict = json.loads(line)</span><br><span class="line">            action = &#123;</span><br><span class="line">                <span class="string">"_index"</span>: <span class="string">"books"</span>,</span><br><span class="line">                <span class="string">"_type"</span>: <span class="string">"books"</span>,</span><br><span class="line">                <span class="comment"># "_id": i,</span></span><br><span class="line">                <span class="string">"_source"</span>: triple_dict</span><br><span class="line">            &#125;</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">            actions.append(action)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            print(<span class="string">f"!!! <span class="subst">&#123;j&#125;</span> th row insert faied: <span class="subst">&#123;line&#125;</span>"</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> count &gt;= max_count:</span><br><span class="line">            helpers.bulk(es, actions)</span><br><span class="line">            actions = []</span><br><span class="line">            count = <span class="number">0</span></span><br><span class="line">            num += <span class="number">1</span></span><br><span class="line">            print(<span class="string">"Insert "</span> + str(num * max_count) + <span class="string">" records."</span>)</span><br><span class="line">helpers.bulk(es, actions)</span><br><span class="line">print(<span class="string">'finish~~~'</span>)</span><br></pre></td></tr></table></figure><h3 id="运行截图"><a href="#运行截图" class="headerlink" title="运行截图"></a>运行截图</h3><img src="/Users/zhangronghui/Library/Application Support/typora-user-images/image-20200401145109065.png" alt="image-20200401145109065" style="zoom:50%;" /><img src="https://i.loli.net/2020/04/01/PSpLFleX5hnNTdW.png" alt="PSpLFleX5hnNTdW" style="zoom: 50%;" /><img src="https://i.loli.net/2020/04/01/vGTe3juAI6baCft.png" alt="vGTe3juAI6baCft" style="zoom:50%;" />]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="研究生课程" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/"/>
    
      <category term="信息系统实训" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/"/>
    
      <category term="提交作业" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A/"/>
    
    
  </entry>
  
  <entry>
    <title>tricks-2020-04-1th-week</title>
    <link href="https://zronghui.github.io/tricks/tricks-2020-04-1th-week.html"/>
    <id>https://zronghui.github.io/tricks/tricks-2020-04-1th-week.html</id>
    <published>2020-04-01T03:52:38.000Z</published>
    <updated>2020-04-09T02:59:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><h1 id="04-01"><a href="#04-01" class="headerlink" title="04-01"></a>04-01</h1><h2 id="快速抠图"><a href="#快速抠图" class="headerlink" title="快速抠图"></a>快速抠图</h2><p><a href="https://bgeraser.com/index.html">Remove Background from Images - Background Eraser</a></p><h2 id="Screen-最简单的屏幕共享"><a href="#Screen-最简单的屏幕共享" class="headerlink" title="Screen - 最简单的屏幕共享"></a>Screen - 最简单的屏幕共享</h2><p><a href="https://www.appinn.com/screen-online/">Screen - 最简单的屏幕共享方式，可视频、语音、屏幕标注，就像在一间办公室一样 - 小众软件</a></p><p><a href="https://www.ghpym.com/andpandownload.html">Android PanDownload v1.2.9 - 果核剥壳</a></p><h2 id="bilibili-ASS-弹幕在线转换"><a href="#bilibili-ASS-弹幕在线转换" class="headerlink" title="bilibili ASS 弹幕在线转换"></a>bilibili ASS 弹幕在线转换</h2><p>默认只能一个一个文件转换，经过修改后可多选</p><p><a href="https://tiansh.github.io/us-danmaku/bilibili/">bilibili ASS 弹幕在线转换</a></p><p><a href="file:///Volumes/Data/PycharmProjects/private/24%20bilibili%20ASS%20%E5%BC%B9%E5%B9%95%E5%9C%A8%E7%BA%BF%E8%BD%AC%E6%8D%A2/bilibili%20ASS%20%E5%BC%B9%E5%B9%95%E5%9C%A8%E7%BA%BF%E8%BD%AC%E6%8D%A2.htm">bilibili ASS 弹幕在线转换-本地版</a></p><h2 id="健身小程序：4分钟-Tabata-健身"><a href="#健身小程序：4分钟-Tabata-健身" class="headerlink" title="健身小程序：4分钟 Tabata 健身"></a>健身小程序：4分钟 Tabata 健身</h2><p><a href="https://www.appinn.com/jianshen-wechat-miniapp/">健身小程序：4分钟 Tabata 健身 - 小众软件</a></p><h2 id="QtScrcpy-Android实时投屏软件"><a href="#QtScrcpy-Android实时投屏软件" class="headerlink" title="QtScrcpy: Android实时投屏软件"></a>QtScrcpy: Android实时投屏软件</h2><p><a href="https://gitee.com/Barryda/QtScrcpy">QtScrcpy: Android实时投屏软件，此应用程序提供USB(或通过TCP/IP)连接的Android设备的显示和控制。它不需要任何root访问权限</a></p><h2 id="幕享投屏"><a href="#幕享投屏" class="headerlink" title="幕享投屏"></a>幕享投屏</h2><p><a href="https://www.iplaysoft.com/p/mu-xiang">幕享投屏 - 快上车！超好用的免费无线投屏软件神器！ - 异次元软件下载</a></p><h2 id="高清杂志网-爬虫"><a href="#高清杂志网-爬虫" class="headerlink" title="高清杂志网 爬虫"></a><del>高清杂志网 爬虫</del></h2><p>现在正在修复中</p><p><a href="http://www.gqzzw.com/class.php">高清杂志网-所有杂志</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl gqzzw -a lastPage&#x3D;&#39;http:&#x2F;&#x2F;www.gqzzw.com&#x2F;type&#x2F;yili&#x2F;9&#39; -a zzname&#x3D;&#39;意林&#39;</span><br><span class="line">scrapy crawl gqzzw -a lastPage&#x3D;&#39;http:&#x2F;&#x2F;www.gqzzw.com&#x2F;type&#x2F;duzh&#x2F;11&#39; -a zzname&#x3D;&#39;读者&#39;</span><br><span class="line">scrapy crawl gqzzw -a lastPage&#x3D;&#39;http:&#x2F;&#x2F;www.gqzzw.com&#x2F;type&#x2F;dzyc&#x2F;2&#39; -a zzname&#x3D;&#39;读者·原创版&#39;</span><br><span class="line">scrapy crawl gqzzw -a lastPage&#x3D;&#39;http:&#x2F;&#x2F;www.gqzzw.com&#x2F;type&#x2F;dzxy&#x2F;9&#39; -a zzname&#x3D;&#39;读者·校园版&#39;</span><br><span class="line">scrapy crawl gqzzw -a lastPage&#x3D;&#39;http:&#x2F;&#x2F;www.gqzzw.com&#x2F;type&#x2F;bjzn&#x2F;4&#39; -a zzname&#x3D;&#39;养生保健指南&#39;</span><br><span class="line">scrapy crawl gqzzw -a lastPage&#x3D;&#39;http:&#x2F;&#x2F;www.gqzzw.com&#x2F;type&#x2F;dzjk&#x2F;5&#39; -a zzname&#x3D;&#39;大众健康&#39;</span><br></pre></td></tr></table></figure><p><a href="http://www.gqzzw.com/type/jssw/6">http://www.gqzzw.com/type/jssw/6</a><br><a href="http://www.gqzzw.com/type/zsjs/3">http://www.gqzzw.com/type/zsjs/3</a></p><p>lastPage: <a href="http://www.gqzzw.com/type/dzyx/4">http://www.gqzzw.com/type/dzyx/4</a><br>zzname: 大众医学</p><p>lastPage: <a href="http://www.gqzzw.com/type/jkbl/4">http://www.gqzzw.com/type/jkbl/4</a><br>zzname: 健康博览</p><p>lastPage: <a href="http://www.gqzzw.com/type/klys/4">http://www.gqzzw.com/type/klys/4</a><br>zzname: 家庭医药·快乐养生</p><p>lastPage: <a href="http://www.gqzzw.com/type/rsjk/4">http://www.gqzzw.com/type/rsjk/4</a><br>zzname: 饮食与健康·下旬刊</p><p><a href="http://www.gqzzw.com/type/yssj/4">高清杂志网-分类</a><br><a href="http://www.gqzzw.com/type/dnah/9">高清杂志网-分类</a></p><p>更多杂志和电子书下载：</p><p><a href="http://www.gqzzw.com/">高清杂志网【官网】</a><br><a href="https://www.pdfzj.com/">PDF之家 – PDF杂志,PDF图书免费下载</a><br><a href="https://www.ifblue.net/">若蓝格| 精品阅读时光精品阅读时光</a><br><a href="https://downmagaz.com/">Download PDF magazines - Magazines Commumity!</a><br><a href="http://www.gutenberg.org/">Gutenberg</a></p><h1 id="04-02"><a href="#04-02" class="headerlink" title="04-02"></a>04-02</h1><h2 id="ProgramCreek"><a href="#ProgramCreek" class="headerlink" title="ProgramCreek"></a>ProgramCreek</h2><p><a href="https://www.programcreek.com/">ProgramCreek.com</a></p><p><a href="https://www.programcreek.com/2015/12/top-10-java-utility-classes/">Top 16 Java Utility Classes</a><br><a href="https://www.programcreek.com/simple-java/">Simple Java</a></p><p>可以用例子学习流行库</p><p><a href="https://www.programcreek.com/python/index/module/?action=index&page=1">Python Example</a></p><p>Python code examples search</p><p><a href="https://www.programcreek.com/python/">Python Example</a></p><h2 id="在线抠图、短信接码"><a href="#在线抠图、短信接码" class="headerlink" title="在线抠图、短信接码"></a>在线抠图、短信接码</h2><p><a href="https://hao.su/2495/">免费短信接码网站 - 不死鸟 - 分享为王</a><br><a href="https://hao.su/2968/">在线抠图 - 不死鸟 - 分享为王</a></p><p>搞定设计在线抠图</p><p><a href="https://www.gaoding.com/koutu">https://www.gaoding.com/koutu</a></p><p>变色龙在线抠图</p><p><a href="https://www.bslong.cn/editor.html">https://www.bslong.cn/editor.html</a></p><p>在线清除背景</p><p><a href="https://www.remove.bg">https://www.remove.bg</a><br><a href="https://bgeraser.com">https://bgeraser.com</a></p><p><a href="https://sspai.com/post/59791">「喜提退税」或者「天降横债」，个税汇算清缴到底是什么？ - 少数派</a></p><p>daemon : 守护进程 。</p><p>是一个运行在后台且不受终端控制的进程，其大多数都是随着系统启动而启动，无特殊情况下会一直保持运行直到系统关闭。</p><p>它的存在为我们用户和系统本身提供有用的服务。常见的有 httpd，mysqld，syslogd 等，一般守护程序名称会以 d 结尾。</p><p><a href="https://chrome.google.com/webstore/category/collection/chrome_themes?hl=zh-CN">Chrome Themes</a> </p><p><strong>14款由 Chrome 团队发布的浏览器主题</strong></p><h2 id="WebSocket，它与HTTP有何不同"><a href="#WebSocket，它与HTTP有何不同" class="headerlink" title="WebSocket，它与HTTP有何不同"></a>WebSocket，它与HTTP有何不同</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&mid=2247484305&idx=1&sn=df434981e616c94f62fc6f44a865375d&chksm=fa80d206cdf75b1032de3f883bae6f57191c9795a6f6bca39d840d449a44eb4130096fc356c4&token=771783635&lang=zh_CN#rd">什么是WebSocket，它与HTTP有何不同？</a></p><p><strong>区别</strong></p><p>HTTP是单向的，客户端发送请求，服务器发送响应</p><p>WebSocket是双向的，在客户端-服务器通信的场景中使用的全双工协议，与HTTP不同，它以ws://或wss://开头。它是一个有状态协议，这意味着客户端和服务器之间的连接将保持活动状态，直到被任何一方（客户端或服务器）终止。在通过客户端和服务器中的任何一方关闭连接之后，连接将从两端终止。</p><p><strong>使用WebSocket的场景</strong></p><p>即时Web应用程序、游戏应用程序、聊天应用程序</p><p><strong>不能使用WebSocket的场景</strong></p><p>如果我们需要通过网络传输的任何实时更新或连续数据流，则可以使用<code>WebSocket</code>。如果我们要获取旧数据，或者只想获取一次数据供应用程序使用，则应该使用<code>HTTP</code>协议，不需要很频繁或仅获取一次的数据可以通过简单的<code>HTTP</code>请求查询，因此在这种情况下最好不要使用<code>WebSocket</code>。</p><p>注意：如果仅加载一次数据，则<code>RESTful</code> <code>Web</code>服务足以从服务器获取数据。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><table><thead><tr><th align="left">WEBSOCKET</th><th align="left">HTTP</th></tr></thead><tbody><tr><td align="left"><code>WebSocket</code>是一种双向通信协议，可以通过重用已建立的连接通道将数据从客户端发送到服务器，或者从服务器发送到客户端。连接保持活动状态，直到被客户端或服务器终止。</td><td align="left"><code>HTTP</code>协议是<code>TCP</code>协议之上的单向协议，<code>TCP</code>是面向连接的传输层协议，我们可以在获得响应HTTP连接关闭后再使用HTTP请求方法来创建连接。</td></tr><tr><td align="left">几乎所有的实时应用程序（如（交易，监视，通知）服务）都使用<code>WebSocket</code>在单个通信通道上接收数据。</td><td align="left">简单的<code>RESTful</code>应用程序使用无状态的<code>HTTP</code>协议。</td></tr><tr><td align="left">所有经常更新的应用程序都应该使用<code>WebSocket</code>，它比<code>HTTP</code>连接更快。</td><td align="left">当我们不想在特定时间内保留连接或不重复使用单个连接来传输数据时使用<code>HTTP</code>，<code>HTTP</code>连接的速度比<code>WebSocket</code>慢。</td></tr></tbody></table><h1 id="04-04"><a href="#04-04" class="headerlink" title="04-04"></a>04-04</h1><h3 id="tmux"><a href="#tmux" class="headerlink" title="tmux"></a>tmux</h3><ul><li><a href="https://linux.cn/article-8421-1.html">使用 tmux 打造更强大的终端</a></li><li><a href="http://blog.jobbole.com/87584/">Tmux 速成教程：技巧和调整</a></li><li><a href="https://tmux-plugins.github.io/tmux-yank/">tmux-yank</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install tmux # ubuntu</span><br><span class="line">$ sudo brew    install tmux    # osX</span><br><span class="line">C-b ?          显示快捷键帮助</span><br><span class="line"></span><br><span class="line">C-b C-o        调换窗口位置，类似与vim 里的C-w</span><br><span class="line">C-b 空格键     采用下一个内置布局</span><br><span class="line">C-b !          把当前窗口变为新窗口</span><br><span class="line">C-b &quot;          模向分隔窗口</span><br><span class="line">C-b %          纵向分隔窗口</span><br><span class="line">C-b q          显示分隔窗口的编号</span><br><span class="line">C-b o          跳到下一个分隔窗口</span><br><span class="line">C-b 上下键     上一个及下一个分隔窗口</span><br><span class="line">C-b ALT-方向键 调整分隔窗口大小</span><br><span class="line">C-b c          创建新窗口</span><br><span class="line">C-b 0~9        选择几号窗口</span><br><span class="line">C-b c          创建新窗口</span><br><span class="line">C-b n          选择下一个窗口</span><br><span class="line">C-b l          切换到最后使用的窗口</span><br><span class="line">C-b p          选择前一个窗口</span><br><span class="line">C-b w          以菜单方式显示及选择窗口</span><br><span class="line">C-b t          显示时钟</span><br><span class="line">C-b ;          切换到最后一个使用的面板</span><br><span class="line">C-b x          关闭面板</span><br><span class="line">C-b &amp;          关闭窗口</span><br><span class="line">C-b s          以菜单方式显示和选择会话</span><br><span class="line"></span><br><span class="line">C-b d          退出tumx，并保存当前会话，这时，tmux仍在后台运行，</span><br><span class="line">               可以通过tmux attach进入 到指定的会话</span><br><span class="line">$ tmux list-sessions</span><br><span class="line"></span><br><span class="line">$ tmux attach-session   # 附加</span><br></pre></td></tr></table></figure><h3 id="tmate"><a href="#tmate" class="headerlink" title="tmate"></a><a href="https://tmate.io/">tmate</a></h3><ul><li><a href="https://linux.cn/article-9096-1.html">https://linux.cn/article-9096-1.html</a></li></ul><h1 id="Golang"><a href="#Golang" class="headerlink" title="Golang"></a>Golang</h1><ul><li><a href="https://golang.org/">golang.org</a></li><li><a href="http://go-search.org/">go-search</a></li><li><a href="https://tour.go-zh.org/">Go 指南</a></li><li><a href="https://www.gitbook.com/book/yar999/gopl-zh/details">Go 语言圣经</a></li><li><a href="https://www.kancloud.cn/kancloud/web-application-with-golang/44163">Go Web 编程 (www.kancloud)</a></li><li><a href="https://wizardforcel.gitbooks.io/build-web-application-with-golang/content/">Go Web 编程 (gitbooks)</a></li></ul><p><a href="https://brewinstall.org/">BrewInstall - Search Any MAC APP and Install them</a></p><p><a href="https://hao.su/3434/">UptimeRobot网站宕机检测 - 不死鸟 - 分享为王</a></p><p><a href="https://www.ghpym.com/smartnovel.html">Smartnovel(人工智能文章创作助手) v0.1 - 果核剥壳</a></p><h1 id="04-05"><a href="#04-05" class="headerlink" title="04-05"></a>04-05</h1><h3 id="自定义的番茄钟"><a href="#自定义的番茄钟" class="headerlink" title="自定义的番茄钟"></a>自定义的番茄钟</h3><p><a href="https://github.com/RoderickQiu/wnr">RoderickQiu/wnr: 💻 Work and rest, with wnr now.</a></p><h3 id="网页悬浮"><a href="#网页悬浮" class="headerlink" title="网页悬浮"></a>网页悬浮</h3><p><a href="https://www.appinn.com/pennywise/">Pennywise - 在浮动窗口中打开任何网站，并置顶显示 [Windows/macOS/Linux] - 小众软件</a><br><a href="https://github.com/kamranahmedse/pennywise">kamranahmedse/pennywise: Cross-platform application to open any website or media in a floating window</a></p><p>未测试的 win 软件</p><p><a href="https://www.appinn.com/extra-buttons/">eXtra Buttons - 给标题栏添加额外的按钮 - 小众软件</a><br><a href="https://www.appinn.com/wintop/">Window On Top - 让任意 Windows 窗口位于顶层 - 小众软件</a><br><a href="https://www.appinn.com/on-top-replica/">On Top Replica - 置顶任意窗口的任意部分工具 - 小众软件</a></p><h2 id="连连看外挂"><a href="#连连看外挂" class="headerlink" title="连连看外挂"></a><del>连连看外挂</del></h2><p>找好 Mac 上弄 安卓QQ 游戏里面的连连看外挂，想想算了，相关项目、工具如下：</p><p><a href="https://github.com/GitHub-Laziji/lianliankan/blob/master/lianliankan.py">lianliankan/lianliankan.py at master · GitHub-Laziji/lianliankan</a><br><a href="https://blog.csdn.net/ibiao/article/details/77859997">pyautogui （一）_Python_静心学习、耐心沉淀-CSDN博客</a><br><a href="https://www.iplaysoft.com/scrcpy.html">Scrcpy - 开源免费在电脑显示手机画面并控制手机的工具 (投屏/录屏/免Root) - 异次元软件下载</a><br><a href="https://github.com/ZhangFengze/QQLianLianKanCheat/blob/master/Cheat/Cheat/main.py">QQLianLianKanCheat/main.py at master · ZhangFengze/QQLianLianKanCheat</a></p><h2 id="正则"><a href="#正则" class="headerlink" title="正则 |"></a>正则 |</h2><p>| 以() 划分边界：</p><img src="https://i.loli.net/2020/04/05/N2jvFw8OlGARxCU.png" alt="N2jvFw8OlGARxCU" style="zoom:50%;" /><img src="/Users/zhangronghui/Library/Application Support/typora-user-images/image-20200405222000791.png" alt="image-20200405222000791" style="zoom:50%;" /><p><a href="https://www.52fzg.com/pcrj/7005.html">AG网页视频解析嗅探下载工具v4.2 支持主流影视网站优酷、腾讯、爱奇艺等 - 无二辅助网</a></p><p><a href="https://www.softwhy.com/texiao-107/">【新提醒】分页代码-数字分页效果-拖动分页特效-蚂蚁部落</a></p><h2 id="diff-软件"><a href="#diff-软件" class="headerlink" title="diff 软件"></a>diff 软件</h2><p><a href="https://linux.cn/article-12067-1.html?utm_source=rss&utm_medium=rss">技术|不喜欢 diff 么？试试 Meld 吧</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">brew cask install meld</span><br><span class="line">meld conway1.py conway2.py</span><br></pre></td></tr></table></figure><p>你可以轻松查看并单击箭头（左右都行）合并文件之间的更改。你甚至可以实时编辑文件（在输入时，Meld 可以用作具有实时比较功能的简单文本编辑器）—只是要记得在关闭窗口之前保存。</p><p>你甚至可以比较和编辑三个不同的文件</p><p>meld conway.py（conway.py 在 Git 中），它将显示自上次 Git 提交以来所做的更改</p><p>如果你运行 meld .，你将看到当前目录（如果位于仓库的根目录，就是整个仓库）中的所有更改</p><p>你还可以比较两个目录，这有时很方便</p><p><a href="http://mall.cnki.net/magazine/magalist/YSSJ.htm">养生大世界杂志-中国知网</a><br><a href="http://mall.cnki.net/magazine/magalist/YSSJ.htm">养生大世界杂志-中国知网</a><br><a href="http://mall.cnki.net/magazine/magadetail/DNBC202002.htm">电脑编程技巧与维护杂志-2020年02期-中国知网</a><br><a href="http://mall.cnki.net/magazine/magadetail/DNJY202002.htm">电脑知识与技术(经验技巧)杂志-2020年02期-中国知网</a><br><a href="http://mall.cnki.net/magazine/magadetail/YSSJ202002.htm">养生大世界杂志-2020年02期-中国知网</a></p><h2 id="灵音播放器"><a href="#灵音播放器" class="headerlink" title="灵音播放器"></a>灵音播放器</h2><p><a href="https://www.appinn.com/lyplayer/">灵音播放器 - 支持下载的音乐播放器 [Windows] - 小众软件</a><br><a href="http://lyplayer.hkjapp.com/">灵音播放器 - 音乐播放器 - 官网</a></p><p><a href="https://segmentfault.com/a/1190000012924855">(8) 5分钟把任意网站变成桌面软件 - 日新亭 - SegmentFault 思否</a></p><p><a href="https://mr-houzi.com/2018/01/24/two-line-code-translate-naviteApp/">两行命令打造一个桌面应用 | 猴子星球|Mr-houzi</a></p><h2 id="网站加速优化"><a href="#网站加速优化" class="headerlink" title="网站加速优化"></a>网站加速优化</h2><p><a href="https://segmentfault.com/a/1190000011867361">(8) 如何打造一个全满分网站 - 日新亭 - SegmentFault 思否</a></p><p>手机上抓包</p><p><a href="https://mr-houzi.com/2019/03/18/use-phone-capture-package/">一次手机上抓包之旅 | 猴子星球|Mr-houzi</a></p><p><a href="https://weibo.com/ttarticle/p/show?id=2309404200174363762670">Python资源整理合集</a></p><p>github 上的开源书籍转换成 pdf？ <a href="https://github.com/astaxie/build-web-application-with-golang">https://github.com/astaxie/build-web-application-with-golang</a><br>快使用 GitBook: <a href="https://github.com/GitbookIO/gitbook/blob/master/docs/setup.md">https://github.com/GitbookIO/gitbook/blob/master/docs/setup.md</a><br>鉴于我看到很多人收藏了本主题，本人特提供以下傻瓜式教程，适合全年龄段观众</p><p>安装 nodejs: <a href="https://nodejs.org/en/">https://nodejs.org/en/</a><br>npm install gitbook-cli -g<br>clone 电子书仓库: <a href="https://github.com/astaxie/build-web-application-with-golang">https://github.com/astaxie/build-web-application-with-golang</a><br>cd build-web-application-with-golang-master\zh<br>gitbook pdf<br>然后就会发现生成了 book.pdf<br><a href="http://www.baidu-x.com/?q=build-web-application-with-golang+pdf">http://www.baidu-x.com/?q=build-web-application-with-golang+pdf</a><br><a href="https://www.gitbook.com/book/astaxie/build-web-application-with-golang/details">https://www.gitbook.com/book/astaxie/build-web-application-with-golang/details</a></p><p><a href="https://regex101.com/">Online regex tester and debugger: PHP, PCRE, Python, Golang and JavaScript</a></p><h2 id="macOS-同时使用有线耳机和蓝牙耳机"><a href="#macOS-同时使用有线耳机和蓝牙耳机" class="headerlink" title="macOS 同时使用有线耳机和蓝牙耳机"></a>macOS 同时使用有线耳机和蓝牙耳机</h2><p>2018年10月11日 23:21</p><p>耳机 macOS</p><ol><li>将蓝牙耳机与有线耳机同时连接到 Mac。</li><li>通过 Spotlight 搜索打开 macOS 系统自带的“音频 MIDI 设置”，点击窗口左下角的 + 号来创建多输出设备，创建后勾选蓝牙耳机和有线耳机。</li><li>点击 多输出设备 可以重新设置名字。</li><li>在设置 / 声音 / 输出 栏选择刚才创建的设备。</li></ol><p><a href="http://www.nicotv.me/">妮可动漫 - 追番or补番的集中营，宅男or腐女的秘密基地</a></p><p><a href="https://www.pi001.com/category/acgtv/">动漫影音- 派导航</a></p><p><a href="http://www.bimibimi.me/">M站_哔咪哔咪,这里是兴趣使然的无名小站_bimibimi</a><br><a href="http://www.bimibimi.me/bangumi/bi/57/">斗罗大陆- 在线&amp;下载 - 哔咪哔咪</a></p><h2 id="去除无用的-CSS-样式表"><a href="#去除无用的-CSS-样式表" class="headerlink" title="去除无用的 CSS 样式表"></a>去除无用的 CSS 样式表</h2><p><a href="https://uncss-online.com/">UnCSS Online!</a></p><img src="https://i.loli.net/2020/04/06/q7EwWjPCeiUYtML.png" alt="q7EwWjPCeiUYtML" style="zoom:50%;" /><p><a href="https://purifycss.online/">PurifyCSS Online - Remove unused CSS</a></p><img src="https://i.loli.net/2020/04/06/GafPyIS768hRcUo.png" alt="GafPyIS768hRcUo" style="zoom:50%;" /><h2 id="在-header-中和-body-末尾加载-JS-的区别，巨坑"><a href="#在-header-中和-body-末尾加载-JS-的区别，巨坑" class="headerlink" title="在 header 中和 body 末尾加载 JS 的区别，巨坑"></a>在 header 中和 body 末尾加载 JS 的区别，巨坑</h2><p><a href="https://blog.csdn.net/wd2014610/article/details/79659073">如何查看yum 安装的软件路径（不要再忘了）_运维_向小凯同学学习-CSDN博客</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="tricks" scheme="https://zronghui.github.io/categories/tricks/"/>
    
    
  </entry>
  
  <entry>
    <title>weekly-contest-182</title>
    <link href="https://zronghui.github.io/Leetcode%20weekly%20contest/weekly-contest-182.html"/>
    <id>https://zronghui.github.io/Leetcode%20weekly%20contest/weekly-contest-182.html</id>
    <published>2020-03-29T05:24:35.000Z</published>
    <updated>2020-03-29T14:46:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><p><a href="https://leetcode.com/contest/weekly-contest-182">Contest - LeetCode</a><br><a href="https://leetcode.com/contest/weekly-contest-182/ranking/">Contest - LeetCode</a></p><p><img src="https://i.loli.net/2020/03/29/W3V4YouLTnPEXjO.png" alt="W3V4YouLTnPEXjO"></p><p>太丢人了</p><ul><li><input checked="" disabled="" type="checkbox"> <a href="https://leetcode.com/contest/weekly-contest-182/problems/find-lucky-integer-in-an-array">Find Lucky Integer in an Array</a><strong>3</strong></li><li><input checked="" disabled="" type="checkbox"> <a href="https://leetcode.com/contest/weekly-contest-182/problems/count-number-of-teams">Count Number of Teams</a><strong>4</strong></li><li><input checked="" disabled="" type="checkbox"> <a href="https://leetcode.com/contest/weekly-contest-182/problems/design-underground-system">Design Underground System</a><strong>5</strong></li><li><input disabled="" type="checkbox"> <a href="https://leetcode.com/contest/weekly-contest-182/problems/find-all-good-strings">Find All Good Strings</a> <strong>8</strong></li></ul><h2 id="Find-Lucky-Integer-in-an-Array"><a href="#Find-Lucky-Integer-in-an-Array" class="headerlink" title="Find Lucky Integer in an Array"></a>Find Lucky Integer in an Array</h2><p>Given an array of integers arr, a lucky integer is an integer which has a frequency in the array equal to its value.</p><p>Return a lucky integer in the array. If there are multiple lucky integers return the largest of them. If there is no lucky integer return -1.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findLucky</span><span class="params">(self, arr: List[int])</span> -&gt; int:</span></span><br><span class="line">        result = <span class="number">-1</span></span><br><span class="line">        d = &#123;i:<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> arr&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">            d[i] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">            <span class="keyword">if</span> i==d[i]:</span><br><span class="line">                result = max(result, i)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h2 id="Count-Number-of-Teams"><a href="#Count-Number-of-Teams" class="headerlink" title="Count Number of Teams"></a>Count Number of Teams</h2><p>长度为 3 的单调上升或下降子序列的个数</p><p>相似的题目：<a href="https://zronghui.github.io/leetcode/leetcode-300-Longest-Increasing-Subsequence.html">leetcode 300. Longest Increasing Subsequence - zronghui的博客</a></p><p>比赛最后才想明白，可惜没做完</p><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>长度为 3，选定中间那个数，然后 前面比它小的数*后面比它大的数=以这个数为第二个数的上升子序列</p><p>举例</p><p>Input: rating = [1,2,3,4]<br>Output: 4</p><p>​                           1 2 3 4</p><p>前面比 i 小的个数   0 1 2 3 </p><p>后面比 i 大的个数   3 2 1 0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0*3 + 1*2 + 2*1 + 3*0 &#x3D; 4</span><br></pre></td></tr></table></figure><p>再把 1234 颠倒过来，再算一遍为 0，最后二者相加4+0=4</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numTeams</span><span class="params">(self, rating: List[int])</span> -&gt; int:</span></span><br><span class="line">        <span class="keyword">return</span> self.helper(rating) + self.helper(rating[::<span class="number">-1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">helper</span><span class="params">(self, l)</span>:</span></span><br><span class="line">        dp1 = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> l]</span><br><span class="line">        dp2 = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> l]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(l)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">                <span class="keyword">if</span> l[j] &lt; l[i]:</span><br><span class="line">                    dp1[i] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(l)<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, len(l)):</span><br><span class="line">                <span class="keyword">if</span> l[j] &gt; l[i]:</span><br><span class="line">                    dp2[i] += <span class="number">1</span></span><br><span class="line">        print(dp1, dp2)</span><br><span class="line">        <span class="keyword">return</span> sum(i*j <span class="keyword">for</span> i, j <span class="keyword">in</span> zip(dp1, dp2))</span><br></pre></td></tr></table></figure><h2 id="Design-Underground-System"><a href="#Design-Underground-System" class="headerlink" title="Design Underground System"></a>Design Underground System</h2><p>Implement the class UndergroundSystem that supports three methods:</p><ol><li>checkIn(int id, string stationName, int t)</li></ol><p>A customer with id card equal to id, gets in the station stationName at time t.<br>A customer can only be checked into one place at a time.<br>2. checkOut(int id, string stationName, int t)</p><p>A customer with id card equal to id, gets out from the station stationName at time t.<br>3. getAverageTime(string startStation, string endStation) </p><p>Returns the average time to travel between the startStation and the endStation.<br>The average time is computed from all the previous traveling from startStation to endStation that happened directly.<br>Call to getAverageTime is always valid.<br>You can assume all calls to checkIn and checkOut methods are consistent. That is, if a customer gets in at time t1 at some station, then it gets out at time t2 with t2 &gt; t1. All events happen in chronological order.</p><p>这题简单，构造 2 个字典就完事</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UndergroundSystem</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># &#123;id: [t, src]&#125;</span></span><br><span class="line">        self.checkInDict = &#123;&#125;</span><br><span class="line">        <span class="comment"># &#123;(src, dest): [sumTime, n]&#125;</span></span><br><span class="line">        self.timeDict = &#123;&#125;</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">checkIn</span><span class="params">(self, id: int, stationName: str, t: int)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        self.checkInDict[id] = [t, stationName]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">checkOut</span><span class="params">(self, id: int, stationName: str, t: int)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        inTime, inStation = self.checkInDict[id]</span><br><span class="line">        <span class="keyword">del</span> self.checkInDict[id]</span><br><span class="line">        <span class="keyword">if</span> (inStation, stationName) <span class="keyword">not</span> <span class="keyword">in</span> self.timeDict:</span><br><span class="line">            self.timeDict[(inStation, stationName)] = [t-inTime, <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.timeDict[(inStation, stationName)][<span class="number">0</span>] += t-inTime</span><br><span class="line">            self.timeDict[(inStation, stationName)][<span class="number">1</span>] += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getAverageTime</span><span class="params">(self, startStation: str, endStation: str)</span> -&gt; float:</span></span><br><span class="line">        sum, n = self.timeDict[(startStation, endStation)]</span><br><span class="line">        <span class="keyword">return</span> sum/n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Your UndergroundSystem object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"># obj = UndergroundSystem()</span></span><br><span class="line"><span class="comment"># obj.checkIn(id,stationName,t)</span></span><br><span class="line"><span class="comment"># obj.checkOut(id,stationName,t)</span></span><br><span class="line"><span class="comment"># param_3 = obj.getAverageTime(startStation,endStation)</span></span><br></pre></td></tr></table></figure><h2 id="Find-All-Good-Strings"><a href="#Find-All-Good-Strings" class="headerlink" title="Find All Good Strings"></a>Find All Good Strings</h2><p>Given the strings s1 and s2 of size n, and the string evil. Return the number of good strings.</p><p>A good string has size n, it is alphabetically greater than or equal to s1, it is alphabetically smaller than or equal to s2, and it does not contain the string evil as a substring. Since the answer can be a huge number, return this modulo 10^9 + 7.</p><p>这道题真的 hard。。。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="Leetcode weekly contest" scheme="https://zronghui.github.io/categories/Leetcode-weekly-contest/"/>
    
    
  </entry>
  
  <entry>
    <title>thoughts</title>
    <link href="https://zronghui.github.io/private/thoughts.html"/>
    <id>https://zronghui.github.io/private/thoughts.html</id>
    <published>2020-03-29T00:58:03.000Z</published>
    <updated>2020-03-29T01:00:27.000Z</updated>
    
    <content type="html"><![CDATA[<div id="hexo-blog-encrypt" data-wpm="不好意思，密码没对哦，在检查检查呢！" data-whm="不好意思，信息无法验证！">  <div class="hbe-input-container">  <input type="password" id="hbePass" placeholder="" />    <label for="hbePass">嗨，请准确无误地输入密码查看哟！</label>    <div class="bottom-line"></div>  </div>  <script id="hbeData" type="hbeData" data-hmacdigest="bcd578f10c8b017d0157fed53a53770e0b49ca67f4e396684864b90d9998795a">d4ddde657b62ae9d724a3e00dfabc05a45fdaf36a8bc4373ea59463028fb879d7feb8b7a65d7d5ead04ef94e89f63e42406e79a4cfc2b0e9f3ed2eb2c4b78519ae43f6ea133ab0dd7c1c2986347ad1a45f219cd4106da9a2efa9a716fcb9e34e0637ed3d1e0a869d88aa11c66aad810b9e84d432362e998598d66230694e9e4bdb50ca4213b03a21115488f8641ecfa1</script></div><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      咦，这是一篇加密文章，好像需要输入密码才能查看呢！
    
    </summary>
    
    
      <category term="private" scheme="https://zronghui.github.io/categories/private/"/>
    
    
  </entry>
  
  <entry>
    <title>pygame</title>
    <link href="https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/pygame.html"/>
    <id>https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/pygame.html</id>
    <published>2020-03-17T08:19:44.000Z</published>
    <updated>2020-03-26T15:47:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><p><a href="https://github.com/hbokmann/Pacman">hbokmann/Pacman: Pacman in Python with PyGame</a><br><a href="https://github.com/brunofalmeida/Pacman-Pygame">brunofalmeida/Pacman-Pygame: A remake of the classic Pac-Man arcade game using Python and Pygame.</a><br><a href="chrome-extension://cdonnmffkdaoajfknoeeecmchibpmkmg/assets/pdf/web/viewer.html?file=http%3A%2F%2Fwww.cogsci.rpi.edu%2F~destem%2Figd%2Fpygame_cheat_sheet.pdf">pygame cheat sheet - pygame_cheat_sheet.pdf</a></p><p><a href="https://realpython.com/pygame-a-primer/#.Vo0sHqOmRRI.reddit">PyGame: A Primer on Game Programming in Python – Real Python</a></p><p><a href="https://github.com/realpython/materials">realpython/materials: Bonus materials, exercises, and example projects for our Python tutorials</a></p><ul><li><a href="https://opengameart.org/"><strong>OpenGameArt.org:</strong></a> sounds, sound effects, sprites, and other artwork</li><li><a href="https://kenney.nl/"><strong>Kenney.nl:</strong></a> sounds, sound effects, sprites, and other artwork</li><li><a href="https://www.gameart2d.com/"><strong>Gamer Art 2D:</strong></a> sprites and other artwork</li><li><a href="http://ccmixter.org/"><strong>CC Mixter:</strong></a> sounds and sound effects</li><li><a href="https://freesound.org/"><strong>Freesound:</strong></a> sounds and sound effects</li></ul><ul><li><a href="https://opengameart.org/art-search?keys=pacman">Search Art | OpenGameArt.org</a><br><a href="https://freesound.org/search/?q=pacman&f=&s=score+desc&advanced=0&g=1">Freesound - sound search</a></li></ul><p><img src="https://i.loli.net/2020/03/20/DcTugKVGLJ6xBd9.png" alt="DcTugKVGLJ6xBd9"></p><h2 id="mac-pygame-无画面的问题"><a href="#mac-pygame-无画面的问题" class="headerlink" title="mac pygame 无画面的问题"></a>mac pygame 无画面的问题</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">brew install sdl smpeg sdl_image sdl_mixer sdl_ttf portmidi hg sdl_mixer portmidi sdl2 sdl2_image sdl2_mixer sdl2_ttf</span><br><span class="line">python3 -m pip install pygame==2.0.0.dev6 --user</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 检验</span></span><br><span class="line">python -m pygame.examples.aliens</span><br></pre></td></tr></table></figure><img src="https://i.loli.net/2020/03/24/yMcYAq4X1oHzZGe.png" alt="yMcYAq4X1oHzZGe" style="zoom: 33%;" />]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="研究生课程" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/"/>
    
      <category term="软件测试" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/"/>
    
    
  </entry>
  
  <entry>
    <title>mongodb</title>
    <link href="https://zronghui.github.io/mongodb.html"/>
    <id>https://zronghui.github.io/mongodb.html</id>
    <published>2020-03-16T02:13:14.000Z</published>
    <updated>2020-03-17T13:39:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><h2 id="快速安装"><a href="#快速安装" class="headerlink" title="快速安装"></a>快速安装</h2><p>MongoDB 已经宣布不再开源，从2019年9月2日开始 ，HomeBrew 也从核心仓库 (#43770) 当中移除了mongodb 模块</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> brew install mongodb</span></span><br><span class="line">brew info mongodb</span><br><span class="line"><span class="meta">#</span><span class="bash"> No available formula with the name <span class="string">"mongodb"</span></span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">brew services stop mongodb</span><br><span class="line">brew uninstall mongodb</span><br><span class="line">brew tap mongodb/brew</span><br><span class="line">brew install mongodb-community</span><br><span class="line">brew services start mongodb-community</span><br></pre></td></tr></table></figure><h3 id="brew"><a href="#brew" class="headerlink" title="brew"></a>brew</h3><blockquote><p>brew 又叫 Homebrew，是 Mac OSX 上的软件包管理工具，能在 Mac 中方便的安装软件或者卸载软件， 只需要一个命令， 非常方便</p><p>brew 类似 ubuntu 系统下的 apt-get 的功能</p><p>安装：<code>/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;</code></p><ul><li>brew list 列出已安装的软件</li><li>brew update 更新 brew</li><li>brew home 用浏览器打开 brew 的官方网站</li><li>brew info 显示软件信息</li><li>brew deps 显示包依赖</li></ul></blockquote><h3 id="安装-mongodb"><a href="#安装-mongodb" class="headerlink" title="安装 mongodb"></a>安装 mongodb</h3><blockquote><p>如果你用 brew install mongodb，可能会报错：<br><code>No available formula with the name &quot;mongodb&quot;</code></p><p>然后你需要的操作是：</p><p><code>brew services stop mongodb</code><br><code>brew uninstall mongodb</code><br><code>brew tap mongodb/brew</code><br><code>brew install mongodb-community</code><br><code>brew services start mongodb-community</code></p></blockquote><blockquote><p>查看 mongodb 版本：mongo。<br>接着在终端中输入 <code>mongod</code>, 新建终端接着输入<code>mongo</code>，连接成功。</p></blockquote><h3 id="文件路径"><a href="#文件路径" class="headerlink" title="文件路径"></a>文件路径</h3><blockquote><p>配置文件：/usr/local/etc/mongod.conf<br>日志目录路径：/usr/local/var/log/mongodb<br>数据目录路径：/usr/local/var/mongodb</p></blockquote><h3 id="启动-amp-amp-停止-mongodb-community-服务器"><a href="#启动-amp-amp-停止-mongodb-community-服务器" class="headerlink" title="启动 &amp;&amp; 停止 mongodb-community 服务器"></a>启动 &amp;&amp; 停止 mongodb-community 服务器</h3><h4 id="mongod-作为服务运行"><a href="#mongod-作为服务运行" class="headerlink" title="mongod 作为服务运行"></a>mongod 作为服务运行</h4><blockquote><p><code>brew services start mongodb-community</code><br><code>brew services stop mongodb-community</code></p></blockquote><h4 id="手动启动-mongod"><a href="#手动启动-mongod" class="headerlink" title="手动启动 mongod"></a>手动启动 mongod</h4><blockquote><p><code>mongod --config /usr/local/etc/mongod.conf</code><br>注意：如果您不包含 –config 带有配置文件路径的选项，则 MongoDB 服务器没有默认配置文件或日志目录路径，并将使用数据目录路径 / data/db。<br>要 mongod 手动关闭，请使用 admin 数据库并运行 db.shutdownServer()：<br><code>mongo admin --eval &quot;db.shutdownServer()&quot;</code></p></blockquote><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.jianshu.com/p/67b3e99bb8e3">Mac下使用brew安装mongodb–2020版 - 简书</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>待rss</title>
    <link href="https://zronghui.github.io/todo/%E5%BE%85rss.html"/>
    <id>https://zronghui.github.io/todo/%E5%BE%85rss.html</id>
    <published>2020-03-14T01:46:58.000Z</published>
    <updated>2020-04-02T13:45:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><p><a href="https://www.macbl.com/app/new?&page=1">新鲜应用 - 马可菠萝</a></p><p><a href="https://windliang.cc/">windliang</a></p><p><a href="http://www.gqzzw.com/">高清杂志网【官网】</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="todo" scheme="https://zronghui.github.io/categories/todo/"/>
    
    
  </entry>
  
  <entry>
    <title>待爬取</title>
    <link href="https://zronghui.github.io/todo/%E5%BE%85%E7%88%AC%E5%8F%96.html"/>
    <id>https://zronghui.github.io/todo/%E5%BE%85%E7%88%AC%E5%8F%96.html</id>
    <published>2020-03-14T01:46:52.000Z</published>
    <updated>2020-03-17T13:39:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><p><a href="https://www.anzhuo52.com/?cat=11&paged=2">K站壁纸 | 安卓绅士网 | 第 2 页</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="todo" scheme="https://zronghui.github.io/categories/todo/"/>
    
    
  </entry>
  
  <entry>
    <title>信息系统实训 第1次作业</title>
    <link href="https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD-%E7%AC%AC1%E6%AC%A1%E4%BD%9C%E4%B8%9A.html"/>
    <id>https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD-%E7%AC%AC1%E6%AC%A1%E4%BD%9C%E4%B8%9A.html</id>
    <published>2020-03-12T10:11:57.000Z</published>
    <updated>2020-03-12T14:24:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">regex = <span class="string">r'1995年6月1日|1995/6/1|1995\-6\-1|1995\-06\-01|1995\-06'</span></span><br><span class="line">s = <span class="string">'•”xxx出生于1995年6月1日” • ”xxx出生于1995/6/1” • ”xxx出生于1995-6-1” • ”xxx出生于1995-06-01” • ”xxx出生于1995-06”'</span></span><br><span class="line">print(re.findall(regex, s))</span><br></pre></td></tr></table></figure><h2 id="运行截图"><a href="#运行截图" class="headerlink" title="运行截图"></a>运行截图</h2><img src="https://i.loli.net/2020/03/12/DTVoqjAr5ZBpt8w.png" alt="DTVoqjAr5ZBpt8w" style="zoom:50%;" />]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="研究生课程" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/"/>
    
      <category term="信息系统实训" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/"/>
    
      <category term="提交作业" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A/"/>
    
    
  </entry>
  
  <entry>
    <title>redis</title>
    <link href="https://zronghui.github.io/%E6%95%B0%E6%8D%AE%E5%BA%93/redis.html"/>
    <id>https://zronghui.github.io/%E6%95%B0%E6%8D%AE%E5%BA%93/redis.html</id>
    <published>2020-03-12T04:20:43.000Z</published>
    <updated>2020-03-12T14:24:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="Mac："><a href="#Mac：" class="headerlink" title="Mac："></a>Mac：</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">brew install redis</span><br><span class="line"><span class="meta">#</span><span class="bash"> To have launchd start redis now and restart at login:</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   brew services start redis</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Or, <span class="keyword">if</span> you don<span class="string">'t want/need a background service you can just run:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">   redis-server /usr/<span class="built_in">local</span>/etc/redis.conf</span></span><br><span class="line">brew update;brew services start redis</span><br><span class="line"></span><br><span class="line">cotEdit /usr/local/etc/redis.conf</span><br><span class="line">注释 bind 127.0.0.1</span><br><span class="line">取消注释 requirepass foobare， 并配置密码</span><br><span class="line"></span><br><span class="line">brew services list                </span><br><span class="line"><span class="meta">#</span><span class="bash"> Name          Status  User         Plist</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> elasticsearch stopped</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> redis         started zhangronghui /Users/zhangronghui/Library/LaunchAgents/homebrew.mxcl.redis.plist</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> unbound       stopped</span></span><br><span class="line"></span><br><span class="line">brew services restart redis</span><br><span class="line">redis-cli -a redispassword</span><br></pre></td></tr></table></figure><h3 id="Linux-上："><a href="#Linux-上：" class="headerlink" title="Linux 上："></a>Linux 上：</h3><img src="https://i.loli.net/2020/03/12/CXDx73TjfPUGYwL.png" alt="CXDx73TjfPUGYwL" style="zoom:33%;" />]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="数据库" scheme="https://zronghui.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
  </entry>
  
  <entry>
    <title>前端工具</title>
    <link href="https://zronghui.github.io/frontEnd/%E5%89%8D%E7%AB%AF%E5%B7%A5%E5%85%B7.html"/>
    <id>https://zronghui.github.io/frontEnd/%E5%89%8D%E7%AB%AF%E5%B7%A5%E5%85%B7.html</id>
    <published>2020-03-11T14:58:26.000Z</published>
    <updated>2020-03-28T06:48:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><p><a href="https://enjoycss.com">Online CSS3 Code Generator With a Simple Graphical Interface - EnjoyCSS</a></p><p><a href="http://daicuo.co/forum-3412-1-1.html">前端常用插件、工具类库汇总 - 站长实用工具 DaiCuoBBs</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="frontEnd" scheme="https://zronghui.github.io/categories/frontEnd/"/>
    
    
  </entry>
  
  <entry>
    <title>信息系统实训 TODO</title>
    <link href="https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD-TODO.html"/>
    <id>https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD-TODO.html</id>
    <published>2020-03-11T08:16:25.000Z</published>
    <updated>2020-03-12T14:24:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><p>sentry</p><p>Redis ?</p><p>swagger</p><p>查询<a href="https://book.douban.com/subject/34894380/?icn=index-topchart-subject">雾行者 (豆瓣)</a></p><p>封面挺好看</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="研究生课程" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/"/>
    
      <category term="信息系统实训" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/"/>
    
    
  </entry>
  
  <entry>
    <title>TODO</title>
    <link href="https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/TODO.html"/>
    <id>https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/TODO.html</id>
    <published>2020-03-11T08:15:47.000Z</published>
    <updated>2020-04-07T05:39:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><a id="more"></a><p><a href="https://github.com/superRaytin/paginationjs">superRaytin/paginationjs: A jQuery plugin to provide simple yet fully customisable pagination.</a></p><p><a href="https://lookao.com/">Lookao</a></p><p><a href="https://mengso.com/">萌搜 为小众而搜</a></p><ul><li><input disabled="" type="checkbox"> 用用户搜索的关键词去豆瓣搜索，再解析回来</li><li><input disabled="" type="checkbox"> 多少 ms 查询到多少条数据</li><li><input checked="" disabled="" type="checkbox"> and or</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[toc]&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>alfred</title>
    <link href="https://zronghui.github.io/Mac/07-alfred.html"/>
    <id>https://zronghui.github.io/Mac/07-alfred.html</id>
    <published>2020-03-10T05:01:41.000Z</published>
    <updated>2020-03-11T07:18:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><h2 id="workflow-search"><a href="#workflow-search" class="headerlink" title="workflow search"></a>workflow search</h2><p><a href="http://www.alfredworkflow.com/">Alfred 2 Workflow List | Search, Install and Share</a></p><h2 id="useful-workflow"><a href="#useful-workflow" class="headerlink" title="useful workflow"></a>useful workflow</h2><h3 id="DevDocs-v1-2-0-Download"><a href="#DevDocs-v1-2-0-Download" class="headerlink" title="DevDocs (v1.2.0) ~ Download"></a><a href="https://github.com/yannickglt/alfred-devdocs">DevDocs</a> (v1.2.0) ~ <a href="https://github.com/zenorocha/alfred-workflows/raw/master/devdocs/devdocs.alfredworkflow">Download</a></h3><p>Search through <a href="http://devdocs.io/">DevDocs</a> documentations by filtering the keyword for each language/library ~ <em>by <a href="https://github.com/yannickglt">@yannickglt</a>.</em></p><blockquote><p>Triggers: <code>cdoc</code>, <code>angular</code>, <code>coffeescript</code>, <code>css</code>, <code>d3</code>, <code>dom</code>, <code>dom_events</code>, <code>git</code>, <code>html</code>, <code>http</code>, <code>javascript</code>, <code>jquery</code>, <code>jqueryui</code>, <code>lodash</code>, <code>php</code>, <code>sass</code>, <code>backbone</code>, <code>c</code>, <code>cpp</code>, <code>chai</code>, <code>cordova</code>, <code>ember</code>, <code>express</code>, <code>go</code>, <code>grunt</code>, <code>haskell</code>, <code>jquerymobile</code>, <code>knockout</code>, <code>laravel</code>, <code>less</code>, <code>maxcdn</code>, <code>moment</code>, <code>node</code>, <code>postgresql</code>, <code>python</code>, <code>redis</code>, <code>requirejs</code>, <code>ruby</code>, <code>rails</code>, <code>sinon</code>, <code>underscore</code>, <code>yii</code>.</p></blockquote><img src="https://i.loli.net/2020/03/10/8gjeZf5NnSlV4Ro.png" alt="8gjeZf5NnSlV4Ro" style="zoom:33%;" /><img src="https://i.loli.net/2020/03/10/yCAK5dBMIcUElaj.png" alt="yCAK5dBMIcUElaj" style="zoom:33%;" /><img src="https://i.loli.net/2020/03/10/AfbnqMrwHaL3i5v.png" alt="AfbnqMrwHaL3i5v" style="zoom:33%;" /><h3 id="Caffeinate-v3-03-0-Download"><a href="#Caffeinate-v3-03-0-Download" class="headerlink" title="Caffeinate (v3.03.0) ~ Download"></a><a href="https://github.com/shawnrice/alfred-2-caffeinate-workflow">Caffeinate</a> (v3.03.0) ~ <a href="https://github.com/zenorocha/alfred-workflows/raw/master/caffeinate/caffeinate.alfredworkflow">Download</a></h3><p>Solves the problem of your computer constantly falling asleep by using OS X’s native command line ~ <em>by <a href="https://github.com/shawnrice/">@shawnrice</a>.</em></p><blockquote><p>Triggers: <code>caff</code>.</p></blockquote><img src="https://i.loli.net/2020/03/10/KiGHQqAyPSLlN1E.png" alt="KiGHQqAyPSLlN1E" style="zoom:33%;" /><h3 id="Emoji-v1-5-0-Download"><a href="#Emoji-v1-5-0-Download" class="headerlink" title="Emoji (v1.5.0) ~ Download"></a><a href="https://github.com/carlosgaldino/alfred-emoji-workflow">Emoji</a> (v1.5.0) ~ <a href="https://github.com/zenorocha/alfred-workflows/raw/master/emoji/emoji.alfredworkflow">Download</a></h3><p>Search for <a href="https://en.wikipedia.org/wiki/Emoji">Emojis</a> used by Basecamp, GitHub, GitLab, Trello, and other services ~ <em>by <a href="https://github.com/carlosgaldino/">@carlosgaldino</a>.</em></p><blockquote><p>Triggers: <code>emoji</code>, <code>emoji [alt key]</code>.</p></blockquote><img src="https://i.loli.net/2020/03/10/yKtOVnTFIoifZBS.png" alt="yKtOVnTFIoifZBS" style="zoom:33%;" /><h3 id="Encode-Decode-v1-8-0-Download"><a href="#Encode-Decode-v1-8-0-Download" class="headerlink" title="Encode/Decode (v1.8.0) ~ Download"></a><a href="https://github.com/willfarrell/alfred-encode-decode-workflow">Encode/Decode</a> (v1.8.0) ~ <a href="https://github.com/zenorocha/alfred-workflows/raw/master/encode-decode/encode-decode.alfredworkflow">Download</a></h3><p>Transform query strings through base64, html, url, and utf-8 encode/decode ~ <em>by <a href="https://github.com/willfarrell/">@willfarrell</a>.</em></p><blockquote><p>Triggers: <code>encode</code>, <code>decode</code>.</p></blockquote><img src="https://i.loli.net/2020/03/10/8uxcZXlPRQtTofe.png" alt="8uxcZXlPRQtTofe" style="zoom:33%;" /><h3 id="GitHub-v1-6-0-Download"><a href="#GitHub-v1-6-0-Download" class="headerlink" title="GitHub (v1.6.0) ~ Download"></a><a href="https://github.com/gharlan/alfred-github-workflow">GitHub</a> (v1.6.0) ~ <a href="https://github.com/zenorocha/alfred-workflows/raw/master/github/github.alfredworkflow">Download</a></h3><p>Easily open <a href="https://github.com/">GitHub</a> repositories and more in the browser ~ <em>by <a href="https://github.com/gharlan/">@gharlan</a>.</em></p><p>P.S.: You have to login before you can use the workflow: <code>gh &gt; login</code>.</p><blockquote><p>Triggers: <code>gh</code>.</p></blockquote><img src="https://cloud.githubusercontent.com/assets/398893/14360273/6d1d54ba-fcaa-11e5-99fb-a9b9976194e2.png" alt="github-1" style="zoom:33%;" /><img src="https://cloud.githubusercontent.com/assets/398893/14360270/6d1ae748-fcaa-11e5-80da-6433c312e452.png" alt="github-2" style="zoom:33%;" /><img src="https://cloud.githubusercontent.com/assets/398893/14360274/6d1eba8a-fcaa-11e5-8815-d7e9ca890542.png" alt="github-3" style="zoom:33%;" /><h3 id="Kill-Process-v1-2-0-Download"><a href="#Kill-Process-v1-2-0-Download" class="headerlink" title="Kill Process (v1.2.0) ~ Download"></a><a href="https://github.com/ngreenstein/alfred-process-killer">Kill Process</a> (v1.2.0) ~ <a href="https://github.com/zenorocha/alfred-workflows/raw/master/kill-process/kill-process.alfredworkflow">Download</a></h3><p>Easily find processes by name and kill them ~ <em>by <a href="https://github.com/ngreenstein">@ngreenstein</a>.</em></p><blockquote><p>Triggers: <code>kill</code>.</p></blockquote><img src="https://cloud.githubusercontent.com/assets/398893/14360276/6d2a33ba-fcaa-11e5-8fa5-4d3703a8129f.png" alt="kill" style="zoom:33%;" /><h3 id="Package-Managers-v3-16-0-Download"><a href="#Package-Managers-v3-16-0-Download" class="headerlink" title="Package Managers (v3.16.0) ~ Download"></a><a href="https://github.com/willfarrell/alfred-pkgman-workflow">Package Managers</a> (v3.16.0) ~ <a href="https://github.com/zenorocha/alfred-workflows/raw/master/package-managers/package-managers.alfredworkflow">Download</a></h3><p>Quick package/plugin/component lookup for your favorite package managers ~ <em>by <a href="https://github.com/willfarrell/">@willfarrell</a>.</em></p><blockquote><p>Triggers: <code>apt-get</code>, <code>apm</code>, <code>bower</code>, <code>brew</code>, <code>chef</code>, <code>cocoa</code>, <code>composer</code>, <code>docker</code>, <code>gems</code>, <code>gradle</code>, <code>grunt</code>, <code>gulp</code>, <code>hex</code>, <code>maven</code>, <code>npm</code>, <code>pear</code>, <code>puppet</code>, <code>pypi</code>, <code>raspbian</code>, <code>rpm</code>, <code>yo</code>.</p></blockquote><img src="https://cloud.githubusercontent.com/assets/398893/14360278/6d2d7f2a-fcaa-11e5-9463-0a909fd4a9bd.png" alt="pm-1" style="zoom:33%;" /><img src="https://cloud.githubusercontent.com/assets/398893/14360277/6d2c5c94-fcaa-11e5-964b-09633238e291.png" alt="pm-2" style="zoom:33%;" /><h3 id="Terminal-→-Finder-v1-6-0-Download"><a href="#Terminal-→-Finder-v1-6-0-Download" class="headerlink" title="Terminal → Finder (v1.6.0) ~ Download"></a><a href="https://github.com/LeEnno/alfred-terminalfinder">Terminal → Finder</a> (v1.6.0) ~ <a href="https://github.com/zenorocha/alfred-workflows/raw/master/terminal-finder/terminal-finder.alfredworkflow">Download</a></h3><p>Open current Finder (or Path Finder) window in Terminal (or iTerm) and vice versa ~ <em>by <a href="https://github.com/LeEnno/">@LeEnno</a>.</em></p><blockquote><p>Triggers: <code>ft</code>, <code>tf</code>, <code>fi</code>, <code>if</code>, <code>pt</code>, <code>tp</code>, <code>pi</code>, <code>ip</code>.</p></blockquote><img src="https://cloud.githubusercontent.com/assets/398893/14360282/6d3a0e3e-fcaa-11e5-8e5b-a8c5a3305962.png" alt="terminal-1" style="zoom: 33%;" /><img src="https://cloud.githubusercontent.com/assets/398893/14360284/6d3d19da-fcaa-11e5-933b-2ce62f83d77e.png" alt="terminal-2" style="zoom:33%;" /><h3 id="ssh-Download"><a href="#ssh-Download" class="headerlink" title="ssh (Download)"></a><a href="https://github.com/isometry/alfredworkflows/tree/master/net.isometry.alfred.ssh">ssh</a> (<a href="https://raw.github.com/isometry/alfredworkflows/master/ssh.alfredworkflow">Download</a>)</h3><p>by <a href="https://github.com/isometry">@isometry</a></p><img src="https://i.loli.net/2020/03/10/biwXPyrx3cWtsoY.png" alt="biwXPyrx3cWtsoY" style="zoom: 50%;" /><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://github.com/zenorocha/alfred-workflows">zenorocha/alfred-workflows: A collection of Alfred 3 and 4 workflows that will rock your world</a><br><a href="https://github.com/hzlzh/AlfredWorkflow.com">hzlzh/AlfredWorkflow.com: A public Collection of Alfred Workflows.</a><br><a href="https://github.com/deanishe/alfred-workflow">deanishe/alfred-workflow: Full-featured library for writing Alfred 3 &amp; 4 workflows</a><br><a href="https://github.com/willfarrell/alfred-workflows">willfarrell/alfred-workflows: Alfred Workflows for Developers</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="Mac" scheme="https://zronghui.github.io/categories/Mac/"/>
    
    
  </entry>
  
  <entry>
    <title>scrapy</title>
    <link href="https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/scrapy.html"/>
    <id>https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/scrapy.html</id>
    <published>2020-03-10T03:26:04.000Z</published>
    <updated>2020-04-02T13:45:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><p><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/tutorial.html">Scrapy入门教程 — Scrapy 0.24.6 文档</a></p><h2 id="helloScrapy"><a href="#helloScrapy" class="headerlink" title="helloScrapy"></a>helloScrapy</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy</span><br><span class="line">scrapy startproject helloScrapy</span><br><span class="line">scrapy genspider volmoe volmoe.com</span><br><span class="line">scrapy genspider douban douban.com</span><br></pre></td></tr></table></figure><h3 id="settings-py"><a href="#settings-py" class="headerlink" title="settings.py"></a>settings.py</h3><p>300 是权重，决定多个 pipeline 执行的顺序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ROBOTSTXT_OBEY = True</span></span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'helloScrapy.pipelines.HelloscrapyPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="pipelines-py"><a href="#pipelines-py" class="headerlink" title="pipelines.py"></a>pipelines.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HelloscrapyPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    处理爬虫所爬取到的数据</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        初始化操作，在爬虫运行过程中只执行一次</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.file = open(<span class="string">'books.json'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="comment"># 现将item数据转为字典类型，再将其保存为json文件</span></span><br><span class="line">        text = json.dumps(dict(item), ensure_ascii=<span class="literal">False</span>) + <span class="string">'\n'</span></span><br><span class="line">        <span class="comment"># 写入本地</span></span><br><span class="line">        self.file.write(text)</span><br><span class="line">        <span class="comment"># 会将item打印到屏幕上，方便观察</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        爬虫关闭时所执行的操作，在爬虫运行过程中只执行一次</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.file.close()</span><br></pre></td></tr></table></figure><h3 id="items-py"><a href="#items-py" class="headerlink" title="items.py"></a>items.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BookItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    book_name = scrapy.Field()</span><br><span class="line">    book_url = scrapy.Field()</span><br><span class="line">    book_desc = scrapy.Field()</span><br></pre></td></tr></table></figure><h3 id="Spider-volmoe-py"><a href="#Spider-volmoe-py" class="headerlink" title="Spider/volmoe.py"></a>Spider/volmoe.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> zhconv <span class="keyword">import</span> convert</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> helloScrapy.items <span class="keyword">import</span> BookItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VolmoeSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'volmoe'</span></span><br><span class="line">    allowed_domains = [<span class="string">'volmoe.com'</span>]</span><br><span class="line">    <span class="comment"># start_urls = [f'https://volmoe.com/l/all,all,all,sortpoint,all,all/&#123;i&#125;.htm' for i in range(1, 2)]</span></span><br><span class="line">    start_urls = [<span class="string">f'https://volmoe.com/l/all,all,all,sortpoint,all,all/<span class="subst">&#123;i&#125;</span>.htm'</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">473</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自动调用 parse ，解析 item URL</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        itemUrlList = list(set(response.xpath(<span class="string">'/html/body/div[7]/table'</span>) \</span><br><span class="line">                               .xpath(<span class="string">'//a/@href'</span>) \</span><br><span class="line">                               .re(<span class="string">r'https://volmoe.com/c/\d+.htm'</span>)))</span><br><span class="line">        <span class="keyword">for</span> itemUrl <span class="keyword">in</span> itemUrlList:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=itemUrl, callback=self.parse_item)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 手动调用 parse_item ，解析 item</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            item = BookItem()</span><br><span class="line">            item[<span class="string">'book_url'</span>] = response.url</span><br><span class="line">            item[<span class="string">'book_name'</span>] = convert(response.xpath(<span class="string">'//div/b/text()'</span>).extract()[<span class="number">0</span>], <span class="string">'zh-cn'</span>)</span><br><span class="line">            item[<span class="string">'book_desc'</span>] = convert(response.xpath(<span class="string">'//*[@id="desc_text"]/text()'</span>).extract()[<span class="number">0</span>].strip(), <span class="string">'zh-cn'</span>)</span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">            <span class="keyword">return</span></span><br></pre></td></tr></table></figure><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ol><li><p>爬取 列表页+详情页 用 rules 更方便，但是我用了，没有生效，所以手动指定函数处理</p></li><li><p>直接在网页上的 xpath 可能会与爬虫请求到的结构不同，所以可以用 scrapy shell “url”， view(response), 在网页上使用 xpath finder , xpath helper 查看指定元素的 xpath</p></li><li><p>scrapy genspider mydomain mydomain.com，最后的 mydomain.com 不用加 http 和 com 后面的/, 如 <del><a href="http://mydomain.com/">http://mydomain.com/</a></del></p></li><li><p>借助 <a href="https://github.com/further-reading/scrapy-gui">https://github.com/further-reading/scrapy-gui</a> 测试 CSS <del>xpath</del></p><img src="https://i.loli.net/2020/03/11/b5X6KtGxNMn7OCv.png" alt="b5X6KtGxNMn7OCv" style="zoom:50%;" /><ol start="5"><li><p>获得的 URL 没有域名时：url = response.urljoin(next)  ?</p></li><li><p>可以在一个爬虫中用 custom_settings <img src="https://i.loli.net/2020/03/12/YLS5ftcphlDMTzx.png" alt="YLS5ftcphlDMTzx" style="zoom: 25%;" /></p></li><li><p>scrapy对request的URL去重 通过 yield scrapy.Request(url, self.parse, dont_filter=False) 里的 dont_filter（默认False） 实现</p></li><li><p>如果命令行里不想看到那么多输出的话，可以加个 -L WARNING 参数运行爬虫，如：scrapy crawl spider1 -L WARNING</p></li><li><p>scrapy shell 设置 UA</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell 'http://www.gqzzw.com/type/bjsh' -s USER_AGENT='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'</span><br></pre></td></tr></table></figure></li></ol></li></ol><pre><code>&lt;img src=&quot;https://i.loli.net/2020/03/12/H84sqghj3rNXpWv.jpg&quot; alt=&quot;H84sqghj3rNXpWv&quot; style=&quot;zoom:50%;&quot; /&gt;</code></pre><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><h3 id="启动所有爬虫-代码启动"><a href="#启动所有爬虫-代码启动" class="headerlink" title="启动所有爬虫 代码启动"></a>启动所有爬虫 代码启动</h3><p><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-10.html">Scrapy教程10- 动态配置爬虫 — scrapy-cookbook 0.2.2 文档</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pretty_errors</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.crawler <span class="keyword">import</span> CrawlerProcess</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> helloScrapy.spiders.gqzzw <span class="keyword">import</span> GqzzwSpider</span><br><span class="line"></span><br><span class="line">pretty_errors.activate()</span><br><span class="line">lastPage = input(<span class="string">'lastPage: '</span>)</span><br><span class="line">zzname = input(<span class="string">'zzname: '</span>)</span><br><span class="line">process = CrawlerProcess(get_project_settings())</span><br><span class="line"><span class="comment"># 传入参数</span></span><br><span class="line">process.crawl(GqzzwSpider, lastPage=lastPage, zzname=zzname)</span><br><span class="line">process.start()  <span class="comment"># the script will block here until the crawling is finished</span></span><br></pre></td></tr></table></figure><h3 id="启动一个爬虫"><a href="#启动一个爬虫" class="headerlink" title="启动一个爬虫"></a>启动一个爬虫</h3><p>scrapy crawl volmoe</p><h3 id="事例-spider"><a href="#事例-spider" class="headerlink" title="事例 spider"></a>事例 spider</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tutorial.items <span class="keyword">import</span> DmozItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DmozSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"dmoz"</span></span><br><span class="line">    allowed_domains = [<span class="string">"dmoz.org"</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/"</span>,</span><br><span class="line">        <span class="string">"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> sel <span class="keyword">in</span> response.xpath(<span class="string">'//ul/li'</span>):</span><br><span class="line">            item = DmozItem()</span><br><span class="line">            item[<span class="string">'title'</span>] = sel.xpath(<span class="string">'a/text()'</span>).extract()</span><br><span class="line">            item[<span class="string">'link'</span>] = sel.xpath(<span class="string">'a/@href'</span>).extract()</span><br><span class="line">            item[<span class="string">'desc'</span>] = sel.xpath(<span class="string">'text()'</span>).extract()</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><h3 id="保存爬取到的数据"><a href="#保存爬取到的数据" class="headerlink" title="保存爬取到的数据"></a>保存爬取到的数据</h3><p>最简单存储爬取的数据的方式是使用 <a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/feed-exports.html#topics-feed-exports">Feed exports</a>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl dmoz -o items.json</span><br></pre></td></tr></table></figure><p>该命令将采用 <a href="http://en.wikipedia.org/wiki/JSON">JSON</a> 格式对爬取的数据进行序列化，生成 <code>items.json</code> 文件。</p><p>在类似本篇教程里这样小规模的项目中，这种存储方式已经足够。 如果需要对爬取到的item做更多更为复杂的操作，您可以编写 <a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/item-pipeline.html#topics-item-pipeline">Item Pipeline</a> 。 </p><h3 id="在Shell中尝试Selector选择器"><a href="#在Shell中尝试Selector选择器" class="headerlink" title="在Shell中尝试Selector选择器"></a>在Shell中尝试Selector选择器</h3><p>为了介绍Selector的使用方法，接下来我们将要使用内置的 <a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/shell.html#topics-shell">Scrapy shell</a> 。Scrapy Shell需要您预装好IPython(一个扩展的Python终端)。</p><p>您需要进入项目的根目录，执行下列命令来启动shell:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell &quot;http:&#x2F;&#x2F;www.dmoz.org&#x2F;Computers&#x2F;Programming&#x2F;Languages&#x2F;Python&#x2F;Books&#x2F;&quot;</span><br></pre></td></tr></table></figure><p>注解</p><p>当您在终端运行Scrapy时，请一定记得给url地址加上引号，否则包含参数的url(例如 <code>&amp;</code> 字符)会导致Scrapy运行失败。</p><p>shell的输出类似:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[ ... Scrapy log here ... ]</span><br><span class="line"></span><br><span class="line">2014-01-23 17:11:42-0400 [default] DEBUG: Crawled (200) &lt;GET http:&#x2F;&#x2F;www.dmoz.org&#x2F;Computers&#x2F;Programming&#x2F;Languages&#x2F;Python&#x2F;Books&#x2F;&gt; (referer: None)</span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x3636b50&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   request    &lt;GET http:&#x2F;&#x2F;www.dmoz.org&#x2F;Computers&#x2F;Programming&#x2F;Languages&#x2F;Python&#x2F;Books&#x2F;&gt;</span><br><span class="line">[s]   response   &lt;200 http:&#x2F;&#x2F;www.dmoz.org&#x2F;Computers&#x2F;Programming&#x2F;Languages&#x2F;Python&#x2F;Books&#x2F;&gt;</span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at 0x3fadc50&gt;</span><br><span class="line">[s]   spider     &lt;Spider &#39;default&#39; at 0x3cebf50&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   shelp()           Shell help (print this help)</span><br><span class="line">[s]   fetch(req_or_url) Fetch request (or URL) and update local objects</span><br><span class="line">[s]   view(response)    View response in a browser</span><br><span class="line"></span><br><span class="line">In [1]:</span><br></pre></td></tr></table></figure><p>当shell载入后，您将得到一个包含response数据的本地 <code>response</code> 变量。输入 <code>response.body</code> 将输出response的包体， 输出 <code>response.headers</code> 可以看到response的包头。</p><p>更为重要的是，当输入 <code>response.selector</code> 时， 您将获取到一个可以用于查询返回数据的selector(选择器)， 以及映射到 <code>response.selector.xpath()</code> 、 <code>response.selector.css()</code> 的 快捷方法(shortcut): <code>response.xpath()</code> 和 <code>response.css()</code> 。</p><p>同时，shell根据response提前初始化了变量 <code>sel</code> 。该selector根据response的类型自动选择最合适的分析规则(XML vs HTML)。</p><p>让我们来试试:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">1</span>]: response.xpath(<span class="string">'//title'</span>)</span><br><span class="line">Out[<span class="number">1</span>]: [&lt;Selector xpath=<span class="string">'//title'</span> data=<span class="string">u'&lt;title&gt;Open Directory - Computers: Progr'</span>&gt;]</span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: response.xpath(<span class="string">'//title'</span>).extract()</span><br><span class="line">Out[<span class="number">2</span>]: [<span class="string">u'&lt;title&gt;Open Directory - Computers: Programming: Languages: Python: Books&lt;/title&gt;'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: response.xpath(<span class="string">'//title/text()'</span>)</span><br><span class="line">Out[<span class="number">3</span>]: [&lt;Selector xpath=<span class="string">'//title/text()'</span> data=<span class="string">u'Open Directory - Computers: Programming:'</span>&gt;]</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: response.xpath(<span class="string">'//title/text()'</span>).extract()</span><br><span class="line">Out[<span class="number">4</span>]: [<span class="string">u'Open Directory - Computers: Programming: Languages: Python: Books'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: response.xpath(<span class="string">'//title/text()'</span>).re(<span class="string">'(\w+):'</span>)</span><br><span class="line">Out[<span class="number">5</span>]: [<span class="string">u'Computers'</span>, <span class="string">u'Programming'</span>, <span class="string">u'Languages'</span>, <span class="string">u'Python'</span>]</span><br></pre></td></tr></table></figure><h3 id="命令行工具"><a href="#命令行工具" class="headerlink" title="命令行工具"></a>命令行工具</h3><p>详见：<a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/commands.html">命令行工具(Command line tools) — Scrapy 0.24.6 文档</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject myproject</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可以指定模板（怎么自定义模板？）</span></span><br><span class="line">scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看 basic 模板</span></span><br><span class="line">scrapy genspider -d basic</span><br><span class="line"></span><br><span class="line">scrapy crawl myspider</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行contract检查, 运行没问题就好</span></span><br><span class="line">scrapy check [-l] &lt;spider&gt;</span><br><span class="line"></span><br><span class="line">scrapy list</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 EDITOR 中设定的编辑器编辑给定的spider</span></span><br><span class="line">scrapy edit spider1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用Scrapy下载器(downloader)下载给定的URL，并将获取到的内容送到标准输出（命令行？）</span></span><br><span class="line">scrapy fetch &lt;url&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> ** 在浏览器中打开给定的URL，并以Scrapy spider获取到的形式展现。 有些时候spider获取到的页面和普通用户看到的并不相同。 因此该命令可以用来检查spider所获取到的页面，并确认这是您所期望的。</span></span><br><span class="line">scrapy view &lt;url&gt;</span><br><span class="line"></span><br><span class="line">scrapy shell [url]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取给定的URL并使用相应的spider分析处理。如果您提供 --callback 选项，则使用spider的该方法处理，否则使用 parse 。</span></span><br><span class="line">scrapy parse &lt;url&gt; [options]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取Scrapy的设定</span></span><br><span class="line">scrapy settings [options]</span><br><span class="line"><span class="meta">$</span><span class="bash"> scrapy settings --get BOT_NAME</span></span><br><span class="line">scrapybot</span><br><span class="line"><span class="meta">$</span><span class="bash"> scrapy settings --get DOWNLOAD_DELAY</span></span><br><span class="line">0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在未创建项目的情况下，运行一个编写在Python文件中的spider。</span></span><br><span class="line">scrapy runspider &lt;spider_file.py&gt;</span><br><span class="line"><span class="meta">$</span><span class="bash"> scrapy runspider myspider.py</span></span><br><span class="line">[ ... spider starts crawling ... ]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出Scrapy版本。配合 -v 运行时，该命令同时输出Python, Twisted以及平台的信息，方便bug提交。</span></span><br><span class="line">scrapy version [-v]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将项目部署到Scrapyd服务？</span></span><br><span class="line">scrapy deploy [ &lt;target:project&gt; | -l &lt;target&gt; | -L ]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行benchmark测试</span></span><br><span class="line">scrapy bench</span><br></pre></td></tr></table></figure><h3 id="items"><a href="#items" class="headerlink" title="items"></a>items</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个 item</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Product</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    price = scrapy.Field()</span><br><span class="line">    stock = scrapy.Field()</span><br><span class="line">    last_updated = scrapy.Field(serializer=str)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># item API和 dict API 非常相似</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 一、与Item配合</span></span><br><span class="line"><span class="comment"># 创建item</span></span><br><span class="line">Product(name=<span class="string">'PC'</span>, price=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 获取字段的值</span></span><br><span class="line">p.get(<span class="string">'name'</span>)</span><br><span class="line">p.get(<span class="string">'name'</span>, <span class="string">'default'</span>)</span><br><span class="line">p[<span class="string">'name'</span>]</span><br><span class="line"><span class="string">'name'</span> <span class="keyword">in</span> product <span class="comment"># True  name 字段是否有填充</span></span><br><span class="line"><span class="string">'last_updated'</span> <span class="keyword">in</span> product.fields <span class="comment"># False  last_updated 是否是声明的字段</span></span><br><span class="line"><span class="comment"># 设置字段的值</span></span><br><span class="line">p[<span class="string">'last_updated'</span>] = <span class="string">'today'</span></span><br><span class="line"><span class="comment"># 获取所有获取到的值</span></span><br><span class="line">p.keys() <span class="comment"># ['price', 'name']</span></span><br><span class="line">p.items() <span class="comment"># [('price', 1000), ('name', 'Desktop PC')]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他任务</span></span><br><span class="line"><span class="comment">#   复制item:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>product2 = Product(product)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>product3 = product2.copy()</span><br><span class="line"><span class="comment">#   根据item创建字典(dict):</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dict(product) <span class="comment"># create a dict from all populated values</span></span><br><span class="line">&#123;<span class="string">'price'</span>: <span class="number">1000</span>, <span class="string">'name'</span>: <span class="string">'Desktop PC'</span>&#125;</span><br><span class="line"><span class="comment">#   根据字典(dict)创建item:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Product(&#123;<span class="string">'name'</span>: <span class="string">'Laptop PC'</span>, <span class="string">'price'</span>: <span class="number">1500</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 扩展Item</span></span><br><span class="line"><span class="comment">#   可以通过继承原始的Item来扩展item(添加更多的字段或者修改某些字段的元数据)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DiscountedProduct</span><span class="params">(Product)</span>:</span></span><br><span class="line">    discount_percent = scrapy.Field(serializer=str)</span><br><span class="line">    discount_expiration_date = scrapy.Field()</span><br><span class="line"><span class="comment"># Item对象</span></span><br><span class="line"><span class="comment"># 字段(Field)对象</span></span><br></pre></td></tr></table></figure><h3 id="选择器-css-xpath"><a href="#选择器-css-xpath" class="headerlink" title="选择器  css xpath"></a>选择器  css xpath</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二者等价</span></span><br><span class="line">response.xpath(<span class="string">'//div/a/text()'</span>).extract()</span><br><span class="line">response.css(<span class="string">'div a::text'</span>).extract()</span><br><span class="line"></span><br><span class="line">response.xpath(<span class="string">'//@class'</span>).extract()  <span class="comment"># 选取所有名为 class 的属性</span></span><br><span class="line">response.xpath(<span class="string">'//article/div[1]'</span>).extract()</span><br><span class="line">response.xpath(<span class="string">'//article/div[last()]'</span>).extract()</span><br><span class="line">response.xpath(<span class="string">'//article/div[last()-1]'</span>).extract()</span><br><span class="line">response.xpath(<span class="string">'//article/div[@lang]'</span>).extract() <span class="comment"># 包含 lang 属性</span></span><br><span class="line">response.xpath(<span class="string">"//article/div[@lang='eng']"</span>).extract() <span class="comment"># lang 属性为 eng</span></span><br><span class="line">response.xpath(<span class="string">'/div/*'</span>).extract() <span class="comment"># 所有子节点</span></span><br><span class="line">response.xpath(<span class="string">'//*'</span>).extract() <span class="comment"># 所有元素</span></span><br><span class="line">response.xpath(<span class="string">'//title[@*]'</span>).extract() <span class="comment"># 所有带属性的 title 元素</span></span><br><span class="line">response.xpath(<span class="string">'//div/a | //div/p'</span>).extract()<span class="comment"># 所有 div 的 a 和 p</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 二者等价</span></span><br><span class="line">response.xpath(<span class="string">'//a/@href'</span>).extract_first()</span><br><span class="line">response.xpath(<span class="string">'a::attr(href)'</span>).extract_first()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 复杂点的用法  href 属性包含 'image'</span></span><br><span class="line">response.xpath(<span class="string">'//a[contains(@href, "iamge")]/@href'</span>).extract()</span><br><span class="line">response.css(<span class="string">'a[href*=image]::attr(href)'</span>).extract()</span><br><span class="line"></span><br><span class="line"><span class="comment"># xpath css 可以嵌套</span></span><br><span class="line">response.xpath(<span class="string">'...'</span>).css(<span class="string">'...'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># re</span></span><br><span class="line">response.xpath(<span class="string">'//a[contains(@href, "image")]/text()'</span>).re(<span class="string">r'Name:\s*(.*)'</span>)</span><br><span class="line"><span class="comment"># re re_first</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 相对XPaths</span></span><br><span class="line"></span><br><span class="line">divs = response.xpath(<span class="string">'//div'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> p <span class="keyword">in</span> divs.xpath(<span class="string">'//p'</span>):  <span class="comment"># this is wrong - gets all &lt;p&gt; from the whole document</span></span><br><span class="line"><span class="comment"># 下面是比较合适的处理方法(注意 .//p XPath的点前缀):</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> p <span class="keyword">in</span> divs.xpath(<span class="string">'.//p'</span>):  <span class="comment"># extracts all &lt;p&gt; inside</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">print</span> p.extract()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 另一种常见的情况将是提取所有直系 &lt;p&gt; 的结果:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> p <span class="keyword">in</span> divs.xpath(<span class="string">'p'</span>):</span><br></pre></td></tr></table></figure><h4 id="获取HTML-注释"><a href="#获取HTML-注释" class="headerlink" title="获取HTML 注释"></a>获取HTML 注释</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"> </span><br><span class="line">html_str = <span class="string">"""</span></span><br><span class="line"><span class="string">&lt;div id="box1"&gt;this from blog.csdn.net/lncxydjq , DO NOT COPY!</span></span><br><span class="line"><span class="string">  &lt;div id="box2"&gt;*****</span></span><br><span class="line"><span class="string">    &lt;!--can u get me, bitch?--&gt;</span></span><br><span class="line"><span class="string">  &lt;/div&gt;</span></span><br><span class="line"><span class="string">&lt;/div&gt;</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"> </span><br><span class="line">html = etree.HTML(html_str)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">print</span> html.xpath(<span class="string">'//div[@id="box1"]/div/node()'</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">print</span> type(html.xpath(<span class="string">'//div[@id="box1"]/div/node()'</span>)[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">print</span> html.xpath(<span class="string">'//div[@id="box1"]/div/node()'</span>)[<span class="number">1</span>].text</span><br><span class="line"> </span><br><span class="line"><span class="string">"""output:</span></span><br><span class="line"><span class="string">&lt;!--can u get me, bitch?--&gt;</span></span><br><span class="line"><span class="string">&lt;type 'lxml.etree._Comment'&gt;</span></span><br><span class="line"><span class="string">can u get me, bitch?</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h3 id="spiders"><a href="#spiders" class="headerlink" title="spiders"></a>spiders</h3><h4 id="传递参数"><a href="#传递参数" class="headerlink" title="传递参数"></a>传递参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl myspider -a category=electronics</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'myspider'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, category=None, *args, **kwargs)</span>:</span></span><br><span class="line">        super(MySpider, self).__init__(*args, **kwargs)</span><br><span class="line">        self.start_urls = [<span class="string">'http://www.example.com/categories/%s'</span> % category]</span><br><span class="line">        <span class="comment"># ...</span></span><br></pre></td></tr></table></figure><h4 id="Spider-类"><a href="#Spider-类" class="headerlink" title="Spider 类"></a>Spider 类</h4><p><strong>name</strong></p><p>唯一标识 spider</p><p><strong>allowed_domains</strong></p><p>包含 spider 允许爬取的域名列表</p><p><strong>start_urls</strong></p><p><strong>start_requests() ?</strong></p><p>必须返回可迭代对象</p><p>逻辑：</p><ol><li>未指定 start_urls: start_requests 生效</li><li>指定 start_urls: make_requests_from_url 生效</li></ol><p>可以使用 start_requests 在启动时以 post 登录某个网站：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [scrapy.FormRequest(<span class="string">"http://www.example.com/login"</span>,</span><br><span class="line">                               formdata=&#123;<span class="string">'user'</span>: <span class="string">'john'</span>, <span class="string">'pass'</span>: <span class="string">'secret'</span>&#125;,</span><br><span class="line">                               callback=self.logged_in)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logged_in</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="comment"># here you would extract links to follow and return Requests for</span></span><br><span class="line">    <span class="comment"># each of them, with another callback</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p><strong>make_requests_from_url(url) ?</strong></p><p>该方法接受一个URL并返回用于爬取的 Request 对象。 该方法在初始化request时被 start_requests() 调用，也被用于转化url为request。</p><p><strong>log(message[, level, component])</strong></p><p>log中自动带上该spider的 name 属性。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'example.com'</span></span><br><span class="line">    allowed_domains = [<span class="string">'example.com'</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://www.example.com/1.html'</span>,</span><br><span class="line">        <span class="string">'http://www.example.com/2.html'</span>,</span><br><span class="line">        <span class="string">'http://www.example.com/3.html'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        self.log(<span class="string">'A response from %s just arrived!'</span> % response.url)</span><br></pre></td></tr></table></figure><p><strong>parse 中返回多个 request 和 item</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> myproject.items <span class="keyword">import</span> MyItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'example.com'</span></span><br><span class="line">    allowed_domains = [<span class="string">'example.com'</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://www.example.com/1.html'</span>,</span><br><span class="line">        <span class="string">'http://www.example.com/2.html'</span>,</span><br><span class="line">        <span class="string">'http://www.example.com/3.html'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        sel = scrapy.Selector(response)</span><br><span class="line">        <span class="keyword">for</span> h3 <span class="keyword">in</span> response.xpath(<span class="string">'//h3'</span>).extract():</span><br><span class="line">            <span class="keyword">yield</span> MyItem(title=h3)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> response.xpath(<span class="string">'//a/@href'</span>).extract():</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url, callback=self.parse)</span><br></pre></td></tr></table></figure><h4 id="CrawlSpider"><a href="#CrawlSpider" class="headerlink" title="CrawlSpider"></a>CrawlSpider</h4><p>继承自 Spider，有一个新属性 rules 和一个可复写的方法 parse_start_url</p><p>Rule(link_extractor, callback=None, cb_kwargs=None, follow=None, process_links=None, process_request=None)</p><p><strong>当编写爬虫规则时，请避免使用 parse 作为回调函数</strong>。 由于 CrawlSpider 使用 parse 方法来实现其逻辑，如果 您覆盖了 parse 方法，crawl spider 将会运行失败。</p><p>Follow 默认为 False</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.contrib.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">from</span> scrapy.contrib.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'example.com'</span></span><br><span class="line">    allowed_domains = [<span class="string">'example.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.example.com'</span>]</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">        <span class="comment"># 提取匹配 'category.php' (但不匹配 'subsection.php') 的链接并跟进链接(没有callback意味着follow默认为True)</span></span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'category\.php'</span>, ), deny=(<span class="string">'subsection\.php'</span>, ))),</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取匹配 'item.php' 的链接并使用spider的parse_item方法进行分析</span></span><br><span class="line">        Rule(LinkExtractor(allow=(<span class="string">'item\.php'</span>, )), callback=<span class="string">'parse_item'</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        self.log(<span class="string">'Hi, this is an item page! %s'</span> % response.url)</span><br><span class="line"></span><br><span class="line">        item = scrapy.Item()</span><br><span class="line">        item[<span class="string">'id'</span>] = response.xpath(<span class="string">'//td[@id="item_id"]/text()'</span>).re(<span class="string">r'ID: (\d+)'</span>)</span><br><span class="line">        item[<span class="string">'name'</span>] = response.xpath(<span class="string">'//td[@id="item_name"]/text()'</span>).extract()</span><br><span class="line">        item[<span class="string">'description'</span>] = response.xpath(<span class="string">'//td[@id="item_description"]/text()'</span>).extract()</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure><h4 id="XMLFeedSpider、CSVFeedSpider、SitemapSpider"><a href="#XMLFeedSpider、CSVFeedSpider、SitemapSpider" class="headerlink" title="XMLFeedSpider、CSVFeedSpider、SitemapSpider"></a>XMLFeedSpider、CSVFeedSpider、SitemapSpider</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">XMLFeedSpider例子</span><br><span class="line">该spider十分易用。下边是其中一个例子:</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> log</span><br><span class="line"><span class="keyword">from</span> scrapy.contrib.spiders <span class="keyword">import</span> XMLFeedSpider</span><br><span class="line"><span class="keyword">from</span> myproject.items <span class="keyword">import</span> TestItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(XMLFeedSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'example.com'</span></span><br><span class="line">    allowed_domains = [<span class="string">'example.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.example.com/feed.xml'</span>]</span><br><span class="line">    iterator = <span class="string">'iternodes'</span> <span class="comment"># This is actually unnecessary, since it's the default value</span></span><br><span class="line">    itertag = <span class="string">'item'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_node</span><span class="params">(self, response, node)</span>:</span></span><br><span class="line">        log.msg(<span class="string">'Hi, this is a &lt;%s&gt; node!: %s'</span> % (self.itertag, <span class="string">''</span>.join(node.extract())))</span><br><span class="line"></span><br><span class="line">        item = TestItem()</span><br><span class="line">        item[<span class="string">'id'</span>] = node.xpath(<span class="string">'@id'</span>).extract()</span><br><span class="line">        item[<span class="string">'name'</span>] = node.xpath(<span class="string">'name'</span>).extract()</span><br><span class="line">        item[<span class="string">'description'</span>] = node.xpath(<span class="string">'description'</span>).extract()</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line">        </span><br><span class="line">CSVFeedSpider例子</span><br><span class="line">下面的例子和之前的例子很像，但使用了 CSVFeedSpider:</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> log</span><br><span class="line"><span class="keyword">from</span> scrapy.contrib.spiders <span class="keyword">import</span> CSVFeedSpider</span><br><span class="line"><span class="keyword">from</span> myproject.items <span class="keyword">import</span> TestItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(CSVFeedSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'example.com'</span></span><br><span class="line">    allowed_domains = [<span class="string">'example.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.example.com/feed.csv'</span>]</span><br><span class="line">    delimiter = <span class="string">';'</span></span><br><span class="line">    headers = [<span class="string">'id'</span>, <span class="string">'name'</span>, <span class="string">'description'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_row</span><span class="params">(self, response, row)</span>:</span></span><br><span class="line">        log.msg(<span class="string">'Hi, this is a row!: %r'</span> % row)</span><br><span class="line"></span><br><span class="line">        item = TestItem()</span><br><span class="line">        item[<span class="string">'id'</span>] = row[<span class="string">'id'</span>]</span><br><span class="line">        item[<span class="string">'name'</span>] = row[<span class="string">'name'</span>]</span><br><span class="line">        item[<span class="string">'description'</span>] = row[<span class="string">'description'</span>]</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">SitemapSpider样例</span><br><span class="line">简单的例子: 使用 parse 处理通过sitemap发现的所有url:</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.contrib.spiders <span class="keyword">import</span> SitemapSpider</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(SitemapSpider)</span>:</span></span><br><span class="line">    sitemap_urls = [<span class="string">'http://www.example.com/sitemap.xml'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span> <span class="comment"># ... scrape item here ...</span></span><br></pre></td></tr></table></figure><h3 id="Item-Pipeline"><a href="#Item-Pipeline" class="headerlink" title="Item Pipeline"></a>Item Pipeline</h3><p>当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理。以下是item pipeline的一些典型应用：</p><ul><li>清理HTML数据</li><li>验证爬取的数据(检查item包含某些字段)</li><li>查重(并丢弃)</li><li>将爬取结果保存到数据库中</li></ul><h4 id="编写自己的-item-pipeline"><a href="#编写自己的-item-pipeline" class="headerlink" title="编写自己的 item pipeline"></a>编写自己的 item pipeline</h4><p><strong>process_item</strong></p><p>返回 item 或 抛出 DropItem 异常</p><p><strong>open_spider</strong></p><p>当spider被开启时，这个方法被调用。</p><p><strong>close_spider</strong><br>当spider被关闭时，这个方法被调用</p><h4 id="Item-pipeline-样例"><a href="#Item-pipeline-样例" class="headerlink" title="Item pipeline 样例"></a>Item pipeline 样例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证价格，同时丢弃没有价格的item</span></span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PricePipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    vat_factor = <span class="number">1.15</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> item[<span class="string">'price'</span>]:</span><br><span class="line">            <span class="keyword">if</span> item[<span class="string">'price_excludes_vat'</span>]:</span><br><span class="line">                item[<span class="string">'price'</span>] = item[<span class="string">'price'</span>] * self.vat_factor</span><br><span class="line">            <span class="keyword">return</span> item</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">"Missing price in %s"</span> % item)</span><br><span class="line">            </span><br><span class="line"><span class="comment"># 将item写入JSON文件</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonWriterPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.file = open(<span class="string">'items.jl'</span>, <span class="string">'wb'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        line = json.dumps(dict(item)) + <span class="string">"\n"</span></span><br><span class="line">        self.file.write(line)</span><br><span class="line">        <span class="keyword">return</span> </span><br><span class="line">      </span><br><span class="line"><span class="comment"># 去重</span></span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DuplicatesPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.ids_seen = set()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> item[<span class="string">'id'</span>] <span class="keyword">in</span> self.ids_seen:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">"Duplicate item found: %s"</span> % item)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.ids_seen.add(item[<span class="string">'id'</span>])</span><br><span class="line">            <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure><h4 id="代理ip"><a href="#代理ip" class="headerlink" title="代理ip"></a>代理ip</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProxyMiddleware</span><span class="params">(object)</span>:</span></span><br><span class="line">    logger = logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_exception</span><span class="params">(self, request, exception, spider)</span>:</span></span><br><span class="line">        self.logger.debug(<span class="string">'Get Exception'</span>)</span><br><span class="line">        request.meta[<span class="string">'proxy'</span>] = get_random_proxy() <span class="comment"># 形如 https://127.0.0.1:9743</span></span><br><span class="line">        <span class="keyword">return</span> request</span><br></pre></td></tr></table></figure><p>settings.py 启动 item pipeline 插件</p><p>从小到大的顺序执行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'myproject.pipelines.PricePipeline'</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="string">'myproject.pipelines.JsonWriterPipeline'</span>: <span class="number">800</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Jobs-暂停，恢复爬虫"><a href="#Jobs-暂停，恢复爬虫" class="headerlink" title="Jobs: 暂停，恢复爬虫"></a>Jobs: 暂停，恢复爬虫</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启用或恢复一个爬虫，都是</span></span><br><span class="line">scrapy crawl douban -s JOBDIR=jobs/douban-1</span><br></pre></td></tr></table></figure><h3 id="爬虫优化"><a href="#爬虫优化" class="headerlink" title="爬虫优化"></a>爬虫优化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加并发</span></span><br><span class="line">CONCURRENT_REQUESTS = <span class="number">100</span></span><br><span class="line"><span class="comment"># 降低log级别</span></span><br><span class="line"><span class="comment"># LOG_LEVEL = 'INFO'</span></span><br><span class="line"><span class="comment"># 禁止cookies</span></span><br><span class="line">COOKIES_ENABLED = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 禁止重试</span></span><br><span class="line">RETRY_ENABLED = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 减小下载超时,有些网站就是慢</span></span><br><span class="line"><span class="comment"># DOWNLOAD_TIMEOUT = 15</span></span><br><span class="line"><span class="comment"># 禁止重定向</span></span><br><span class="line">REDIRECT_ENABLED = <span class="literal">False</span></span><br></pre></td></tr></table></figure><h2 id="课上教的"><a href="#课上教的" class="headerlink" title="课上教的"></a>课上教的</h2><h3 id="1-延迟获取"><a href="#1-延迟获取" class="headerlink" title="1 延迟获取"></a><strong>1</strong> 延迟获取</h3><h4 id="1-1-DOWNLOAD-DELAY"><a href="#1-1-DOWNLOAD-DELAY" class="headerlink" title="1.1 DOWNLOAD_DELAY"></a><strong>1.1</strong> DOWNLOAD_DELAY</h4><p>settings.py</p><p>设置DOWNLOAD_DELAY</p><p>数值越大，延迟越大。</p><h4 id="1-3-滚动加载"><a href="#1-3-滚动加载" class="headerlink" title="1.3 滚动加载"></a>1.3 滚动加载</h4><p>像那种页面滚动到下方，才新加载数据的网页，可以通过selenium执行脚本来实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先导入包</span></span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> TimeoutException</span><br><span class="line"><span class="comment"># 然后输入代码</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  spider.browser.get(request.url)</span><br><span class="line">  spider.browser.execute_script(<span class="string">'window.scrollTo(0, document.body.scrollHeight)'</span>)</span><br><span class="line"><span class="keyword">except</span> TimeoutException <span class="keyword">as</span> e:</span><br><span class="line">  print(<span class="string">'超时'</span>)</span><br><span class="line">  spider.browser.execute_script(<span class="string">'window.stop()'</span>)</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">return</span> HtmlResponse(url=spider.browser.current_url, body=spider.browser.page_source, encoding=<span class="string">"utf-8"</span>, request=request)</span><br></pre></td></tr></table></figure><p>滚动到页面底部的操作可以通过javascript代码’window.scrollTo(0, document.body.scrollHeight)’，来实现，所以要执行该脚本，方法是execute_script</p><h3 id="2-settings-py"><a href="#2-settings-py" class="headerlink" title="2 settings.py"></a><strong>2</strong> settings.py</h3><p>参考网址：<a href="https://www.cnblogs.com/longyunfeigu/p/9494408.html">scrapy的配置文件settings - 龙云飞谷 - 博客园</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#==&gt;第一部分：基本配置&lt;===</span></span><br><span class="line"><span class="comment">#1、项目名称，默认的USER_AGENT由它来构成，也作为日志记录的日志名</span></span><br><span class="line">BOT_NAME = <span class="string">'Amazon'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2、爬虫应用路径</span></span><br><span class="line">SPIDER_MODULES = [<span class="string">'Amazon.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'Amazon.spiders'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#3、客户端User-Agent请求头</span></span><br><span class="line"><span class="comment">#USER_AGENT = 'Amazon (+http://www.yourdomain.com)'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#4、是否遵循爬虫协议</span></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#5、是否支持cookie，cookiejar进行操作cookie，默认开启</span></span><br><span class="line"><span class="comment">#COOKIES_ENABLED = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#6、Telnet用于查看当前爬虫的信息，操作爬虫等...使用telnet ip port ，然后通过命令操作</span></span><br><span class="line"><span class="comment">#TELNETCONSOLE_ENABLED = False</span></span><br><span class="line"><span class="comment">#TELNETCONSOLE_HOST = '127.0.0.1'</span></span><br><span class="line"><span class="comment">#TELNETCONSOLE_PORT = [6023,]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#7、Scrapy发送HTTP请求默认使用的请求头</span></span><br><span class="line"><span class="comment">#DEFAULT_REQUEST_HEADERS = &#123;</span></span><br><span class="line"><span class="comment">#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',</span></span><br><span class="line"><span class="comment">#   'Accept-Language': 'en',</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#===&gt;第二部分：并发与延迟&lt;===</span></span><br><span class="line"><span class="comment">#1、下载器总共最大处理的并发请求数,默认值16</span></span><br><span class="line"><span class="comment">#CONCURRENT_REQUESTS = 32</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2、每个域名能够被执行的最大并发请求数目，默认值8</span></span><br><span class="line"><span class="comment">#CONCURRENT_REQUESTS_PER_DOMAIN = 16</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#3、能够被单个IP处理的并发请求数，默认值0，代表无限制，需要注意两点</span></span><br><span class="line"><span class="comment">#I、如果不为零，那CONCURRENT_REQUESTS_PER_DOMAIN将被忽略，即并发数的限制是按照每个IP来计算，而不是每个域名</span></span><br><span class="line"><span class="comment">#II、该设置也影响DOWNLOAD_DELAY，如果该值不为零，那么DOWNLOAD_DELAY下载延迟是限制每个IP而不是每个域</span></span><br><span class="line"><span class="comment">#CONCURRENT_REQUESTS_PER_IP = 16</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#4、如果没有开启智能限速，这个值就代表一个规定死的值，代表对同一网址延迟请求的秒数</span></span><br><span class="line"><span class="comment">#DOWNLOAD_DELAY = 3</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#===&gt;第三部分：智能限速/自动节流：AutoThrottle extension&lt;===</span></span><br><span class="line"><span class="comment">#一：介绍</span></span><br><span class="line"><span class="keyword">from</span> scrapy.contrib.throttle <span class="keyword">import</span> AutoThrottle <span class="comment">#http://scrapy.readthedocs.io/en/latest/topics/autothrottle.html#topics-autothrottle</span></span><br><span class="line">设置目标：</span><br><span class="line"><span class="number">1</span>、比使用默认的下载延迟对站点更好</span><br><span class="line"><span class="number">2</span>、自动调整scrapy到最佳的爬取速度，所以用户无需自己调整下载延迟到最佳状态。用户只需要定义允许最大并发的请求，剩下的事情由该扩展组件自动完成</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#二：如何实现？</span></span><br><span class="line">在Scrapy中，下载延迟是通过计算建立TCP连接到接收到HTTP包头(header)之间的时间来测量的。</span><br><span class="line">注意，由于Scrapy可能在忙着处理spider的回调函数或者无法下载，因此在合作的多任务环境下准确测量这些延迟是十分苦难的。 不过，这些延迟仍然是对Scrapy(甚至是服务器)繁忙程度的合理测量，而这扩展就是以此为前提进行编写的。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#三：限速算法</span></span><br><span class="line">自动限速算法基于以下规则调整下载延迟</span><br><span class="line"><span class="comment">#1、spiders开始时的下载延迟是基于AUTOTHROTTLE_START_DELAY的值</span></span><br><span class="line"><span class="comment">#2、当收到一个response，对目标站点的下载延迟=收到响应的延迟时间/AUTOTHROTTLE_TARGET_CONCURRENCY</span></span><br><span class="line"><span class="comment">#3、下一次请求的下载延迟就被设置成：对目标站点下载延迟时间和过去的下载延迟时间的平均值</span></span><br><span class="line"><span class="comment">#4、没有达到200个response则不允许降低延迟</span></span><br><span class="line"><span class="comment">#5、下载延迟不能变的比DOWNLOAD_DELAY更低或者比AUTOTHROTTLE_MAX_DELAY更高</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#四：配置使用</span></span><br><span class="line"><span class="comment">#开启True，默认False</span></span><br><span class="line">AUTOTHROTTLE_ENABLED = <span class="literal">True</span></span><br><span class="line"><span class="comment">#起始的延迟</span></span><br><span class="line">AUTOTHROTTLE_START_DELAY = <span class="number">5</span></span><br><span class="line"><span class="comment">#最小延迟</span></span><br><span class="line">DOWNLOAD_DELAY = <span class="number">3</span></span><br><span class="line"><span class="comment">#最大延迟</span></span><br><span class="line">AUTOTHROTTLE_MAX_DELAY = <span class="number">10</span></span><br><span class="line"><span class="comment">#每秒并发请求数的平均值，不能高于 CONCURRENT_REQUESTS_PER_DOMAIN或CONCURRENT_REQUESTS_PER_IP，调高了则吞吐量增大强奸目标站点，调低了则对目标站点更加”礼貌“</span></span><br><span class="line"><span class="comment">#每个特定的时间点，scrapy并发请求的数目都可能高于或低于该值，这是爬虫视图达到的建议值而不是硬限制</span></span><br><span class="line">AUTOTHROTTLE_TARGET_CONCURRENCY = <span class="number">16.0</span></span><br><span class="line"><span class="comment">#调试</span></span><br><span class="line">AUTOTHROTTLE_DEBUG = <span class="literal">True</span></span><br><span class="line">CONCURRENT_REQUESTS_PER_DOMAIN = <span class="number">16</span></span><br><span class="line">CONCURRENT_REQUESTS_PER_IP = <span class="number">16</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#===&gt;第四部分：爬取深度与爬取方式&lt;===</span></span><br><span class="line"><span class="comment">#1、爬虫允许的最大深度，可以通过meta查看当前深度；0表示无深度</span></span><br><span class="line"><span class="comment"># DEPTH_LIMIT = 3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2、爬取时，0表示深度优先Lifo(默认)；1表示广度优先FiFo</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 后进先出，深度优先</span></span><br><span class="line"><span class="comment"># DEPTH_PRIORITY = 0</span></span><br><span class="line"><span class="comment"># SCHEDULER_DISK_QUEUE = 'scrapy.squeue.PickleLifoDiskQueue'</span></span><br><span class="line"><span class="comment"># SCHEDULER_MEMORY_QUEUE = 'scrapy.squeue.LifoMemoryQueue'</span></span><br><span class="line"><span class="comment"># 先进先出，广度优先</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># DEPTH_PRIORITY = 1</span></span><br><span class="line"><span class="comment"># SCHEDULER_DISK_QUEUE = 'scrapy.squeue.PickleFifoDiskQueue'</span></span><br><span class="line"><span class="comment"># SCHEDULER_MEMORY_QUEUE = 'scrapy.squeue.FifoMemoryQueue'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#3、调度器队列</span></span><br><span class="line"><span class="comment"># SCHEDULER = 'scrapy.core.scheduler.Scheduler'</span></span><br><span class="line"><span class="comment"># from scrapy.core.scheduler import Scheduler</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#4、访问URL去重</span></span><br><span class="line"><span class="comment"># DUPEFILTER_CLASS = 'step8_king.duplication.RepeatUrl'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#===&gt;第五部分：中间件、Pipelines、扩展&lt;===</span></span><br><span class="line"><span class="comment">#1、Enable or disable spider middlewares</span></span><br><span class="line"><span class="comment"># See http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html</span></span><br><span class="line"><span class="comment">#SPIDER_MIDDLEWARES = &#123;</span></span><br><span class="line"><span class="comment">#    'Amazon.middlewares.AmazonSpiderMiddleware': 543,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2、Enable or disable downloader middlewares</span></span><br><span class="line"><span class="comment"># See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="comment"># 'Amazon.middlewares.DownMiddleware1': 543,</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#3、Enable or disable extensions</span></span><br><span class="line"><span class="comment"># See http://scrapy.readthedocs.org/en/latest/topics/extensions.html</span></span><br><span class="line"><span class="comment">#EXTENSIONS = &#123;</span></span><br><span class="line"><span class="comment">#    'scrapy.extensions.telnet.TelnetConsole': None,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#4、Configure item pipelines</span></span><br><span class="line"><span class="comment"># See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="comment"># 'Amazon.pipelines.CustomPipeline': 200,</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#===&gt;第六部分：缓存&lt;===</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">1. 启用缓存</span></span><br><span class="line"><span class="string">    目的用于将已经发送的请求或相应缓存下来，以便以后使用</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    from scrapy.downloadermiddlewares.httpcache import HttpCacheMiddleware</span></span><br><span class="line"><span class="string">    from scrapy.extensions.httpcache import DummyPolicy</span></span><br><span class="line"><span class="string">    from scrapy.extensions.httpcache import FilesystemCacheStorage</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># 是否启用缓存策略</span></span><br><span class="line"><span class="comment"># HTTPCACHE_ENABLED = True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 缓存策略：所有请求均缓存，下次在请求直接访问原来的缓存即可</span></span><br><span class="line"><span class="comment"># HTTPCACHE_POLICY = "scrapy.extensions.httpcache.DummyPolicy"</span></span><br><span class="line"><span class="comment"># 缓存策略：根据Http响应头：Cache-Control、Last-Modified 等进行缓存的策略</span></span><br><span class="line"><span class="comment"># HTTPCACHE_POLICY = "scrapy.extensions.httpcache.RFC2616Policy"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 缓存超时时间</span></span><br><span class="line"><span class="comment"># HTTPCACHE_EXPIRATION_SECS = 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 缓存保存路径</span></span><br><span class="line"><span class="comment"># HTTPCACHE_DIR = 'httpcache'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 缓存忽略的Http状态码</span></span><br><span class="line"><span class="comment"># HTTPCACHE_IGNORE_HTTP_CODES = []</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 缓存存储的插件</span></span><br><span class="line"><span class="comment"># HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'</span></span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://juejin.im/post/5aec1bb9f265da0b9526f855">Scrapy框架的使用之Selector的用法 - 掘金</a></p><p>介绍了 css xpath re 的用法</p><h2 id="工具-–-Useful-packages"><a href="#工具-–-Useful-packages" class="headerlink" title="工具 – Useful packages"></a>工具 – Useful packages</h2><p><a href="https://github.com/further-reading/scrapy-gui">further-reading/scrapy-gui: A simple, Qt-Webengine powered web browser with built in functionality for basic scrapy webscraping support.</a></p><p>今天在豆瓣失败了，大多还是很好用的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ipython</span><br><span class="line"><span class="keyword">import</span> scrapy_gui</span><br><span class="line">scrapy_gui.open_browser()</span><br></pre></td></tr></table></figure><img src="https://i.loli.net/2020/03/11/b5X6KtGxNMn7OCv.png" alt="b5X6KtGxNMn7OCv" style="zoom:50%;" /><h3 id="gerapy"><a href="#gerapy" class="headerlink" title="gerapy"></a>gerapy</h3><p>主要用来管理本地或远程主机的 scrapy 项目，替代 scrapyd 的命令行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pip3 install gerapy</span><br><span class="line">gerapy init</span><br><span class="line">gerapy init &lt;workspace&gt; # 留空 为 gerapy</span><br><span class="line">cd gerapy</span><br><span class="line">gerapy migrate</span><br><span class="line">gerapy createsuperuser</span><br><span class="line">gerapy runserver</span><br></pre></td></tr></table></figure><p><a href="https://github.com/Gerapy/Gerapy">Gerapy/Gerapy: Distributed Crawler Management Framework Based on Scrapy, Scrapyd, Django and Vue.js</a><br><a href="https://ask.hellobi.com/blog/cuiqingcai/11195#articleHeader5">跟繁琐的命令行说拜拜！Gerapy分布式爬虫管理框架来袭！ - 天善智能：专注于商业智能BI和数据分析、大数据领域的垂直社区平台</a><br><a href="https://blog.csdn.net/baidu_32542573/article/details/79722390">python爬虫之Gerapy安装部署_Python_baidu_32542573的博客-CSDN博客</a></p><h2 id="防止封IP策略"><a href="#防止封IP策略" class="headerlink" title="防止封IP策略"></a>防止封IP策略</h2><p><a href="https://github.com/yidao620c/core-scrapy#">yidao620c/core-scrapy: python-scrapy demo</a></p><p>如果抓取太频繁了，就被被封IP</p><p>策略1：设置download_delay下载延迟，数字设置为5秒，越大越安全<br>策略2：禁止Cookie，某些网站会通过Cookie识别用户身份，禁用后使得服务器无法识别爬虫轨迹<br>策略3：使用user agent池。也就是每次发送的时候随机从池中选择不一样的浏览器头信息，防止暴露爬虫身份<br>策略4：使用IP池，这个需要大量的IP资源，貌似还达不到这个要求<br>策略5：分布式爬取，这个是针对大型爬虫系统的，对目前而言我们还用不到。</p><p>scrapy crawl shudan -s JOBDIR=jobs/shudan-1</p><h2 id="scrapy-cookbook"><a href="#scrapy-cookbook" class="headerlink" title="scrapy-cookbook"></a>scrapy-cookbook</h2><p>Contents:</p><ul><li>Scrapy教程01- 入门篇<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-01.html#scrapy">安装scrapy</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-01.html#">简单示例</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-01.html#scrapy">Scrapy特性一览</a></li></ul></li><li>Scrapy教程02- 完整示例<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-02.html#scrapy">创建Scrapy工程</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-02.html#item">定义我们的Item</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-02.html#spider">第一个Spider</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-02.html#">运行爬虫</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-02.html#">处理链接</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-02.html#">导出抓取数据</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-02.html#">保存数据到数据库</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-02.html#">下一步</a></li></ul></li><li>Scrapy教程03- Spider详解<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-03.html#crawlspider">CrawlSpider</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-03.html#xmlfeedspider">XMLFeedSpider</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-03.html#csvfeedspider">CSVFeedSpider</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-03.html#sitemapspider">SitemapSpider</a></li></ul></li><li>Scrapy教程04- Selector详解<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-04.html#">关于选择器</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-04.html#">使用选择器</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-04.html#">嵌套选择器</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-04.html#">使用正则表达式</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-04.html#xpath">XPath相对路径</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-04.html#xpath">XPath建议</a></li></ul></li><li>Scrapy教程05- Item详解<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-05.html#item">定义Item</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-05.html#item-fields">Item Fields</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-05.html#item">Item使用示例</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-05.html#item-loader">Item Loader</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-05.html#">输入/输出处理器</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-05.html#item-loader">自定义Item Loader</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-05.html#field">在Field定义中声明输入/输出处理器</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-05.html#item-loader">Item Loader上下文</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-05.html#">内置的处理器</a></li></ul></li><li>Scrapy教程06- Item Pipeline<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-06.html#pipeline">编写自己的Pipeline</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-06.html#item-pipeline">Item Pipeline示例</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-06.html#item-pipeline">激活一个Item Pipeline组件</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-06.html#feed-exports">Feed exports</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-06.html#">请求和响应</a></li></ul></li><li>Scrapy教程07- 内置服务<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-07.html#email">发送email</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-07.html#spider">同一个进程运行多个Spider</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-07.html#">分布式爬虫</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-07.html#">防止被封的策略</a></li></ul></li><li>Scrapy教程08- 文件与图片<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-08.html#files-pipeline">使用Files Pipeline</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-08.html#images-pipeline">使用Images Pipeline</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-08.html#">使用例子</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-08.html#">自定义媒体管道</a></li></ul></li><li>Scrapy教程09- 部署<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-09.html#scrapyd">部署到Scrapyd</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-09.html#scrapy-cloud">部署到Scrapy Cloud</a></li></ul></li><li>Scrapy教程10- 动态配置爬虫<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-10.html#scrapy">脚本运行Scrapy</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-10.html#spider">同一进程运行多个spider</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-10.html#">定义规则表</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-10.html#item">定义文章Item</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-10.html#articlespider">定义ArticleSpider</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-10.html#pipeline">编写pipeline存储到数据库中</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-10.html#run-py">修改run.py启动脚本</a></li></ul></li><li>Scrapy教程11- 模拟登录<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-11.html#start-requests">重写start_requests方法</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-11.html#formrequest">使用FormRequest</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-11.html#requests-to-follow">重写_requests_to_follow</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-11.html#">页面处理方法</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-11.html#">完整源码</a></li></ul></li><li>Scrapy教程12- 抓取动态网站<ul><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-12.html#scrapy-splash">scrapy-splash简介</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-12.html#docker">安装docker</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-12.html#splash">安装Splash</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-12.html#scrapy-splash">安装scrapy-splash</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-12.html#scrapy-splash">配置scrapy-splash</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-12.html#scrapy-splash">使用scrapy-splash</a></li><li><a href="https://scrapy-cookbook.readthedocs.io/zh_CN/latest/scrapy-12.html#">使用实例</a></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="研究生课程" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/"/>
    
      <category term="信息系统实训" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/"/>
    
    
  </entry>
  
  <entry>
    <title>信息系统实训 第二次作业</title>
    <link href="https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD-%E7%AC%AC2%E6%AC%A1%E4%BD%9C%E4%B8%9A.html"/>
    <id>https://zronghui.github.io/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD-%E7%AC%AC2%E6%AC%A1%E4%BD%9C%E4%B8%9A.html</id>
    <published>2020-03-10T00:45:02.000Z</published>
    <updated>2020-03-12T14:24:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><a id="more"></a><p>书籍搜索引擎</p><h2 id="任务一"><a href="#任务一" class="headerlink" title="任务一"></a>任务一</h2><h3 id="选择其中一个要爬取的网站"><a href="#选择其中一个要爬取的网站" class="headerlink" title="选择其中一个要爬取的网站"></a>选择其中一个要爬取的网站</h3><p><a href="https://volmoe.com/">Vol.moe [Kindle漫画|Kobo漫画|epub漫画]</a></p><h3 id="选择想爬取数据项（尽量全）"><a href="#选择想爬取数据项（尽量全）" class="headerlink" title="选择想爬取数据项（尽量全）"></a>选择想爬取数据项（尽量全）</h3><p>书籍名 书籍链接 书籍详情</p><img src="https://i.loli.net/2020/03/10/37r9Qo1dtHCmxLS.png" alt="37r9Qo1dtHCmxLS" style="zoom: 50%;" /><h3 id="确定数据项所在网页之间的跳转关系，绘制它们的url树"><a href="#确定数据项所在网页之间的跳转关系，绘制它们的url树" class="headerlink" title="确定数据项所在网页之间的跳转关系，绘制它们的url树"></a>确定数据项所在网页之间的跳转关系，绘制它们的url树</h3><p>说明：共 471 个分页，一个分页有 18 个详情页</p><img src="https://i.loli.net/2020/03/10/e1DENgTSL2FBsiv.png" alt="e1DENgTSL2FBsiv" style="zoom: 50%;" /><h3 id="写出url树的深度优先遍历、广度优先遍历顺序"><a href="#写出url树的深度优先遍历、广度优先遍历顺序" class="headerlink" title="写出url树的深度优先遍历、广度优先遍历顺序"></a>写出url树的深度优先遍历、广度优先遍历顺序</h3><p><strong>深度优先遍历</strong>: A B E F C G H D</p><p><strong>广度优先遍历</strong>: A B C D E F G H</p><h2 id="任务二"><a href="#任务二" class="headerlink" title="任务二"></a>任务二</h2><h3 id="选择要爬取的数据项所在的其中一个网页"><a href="#选择要爬取的数据项所在的其中一个网页" class="headerlink" title="选择要爬取的数据项所在的其中一个网页"></a>选择要爬取的数据项所在的其中一个网页</h3><p><a href="https://volmoe.com/c/50066.htm">灭鬼之刃: 吾峠呼世晴[Kindle漫画|epub漫画] [volmoe.com]</a></p><h3 id="对想爬取的数据项绘制出它们的dom树"><a href="#对想爬取的数据项绘制出它们的dom树" class="headerlink" title="对想爬取的数据项绘制出它们的dom树"></a>对想爬取的数据项绘制出它们的dom树</h3><p>Xpath:</p><p>书籍名：//div/b/text()</p><p>书籍详情：//*[@id=”desc_text”]/text()</p><p>爬取结果：</p><img src="https://i.loli.net/2020/03/12/vWZG6kezTg4HuKP.png" alt="vWZG6kezTg4HuKP" style="zoom: 50%;" />]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
    
    </summary>
    
    
      <category term="研究生课程" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/"/>
    
      <category term="信息系统实训" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/"/>
    
      <category term="提交作业" scheme="https://zronghui.github.io/categories/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%AF%BE%E7%A8%8B/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%AE%AD/%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A/"/>
    
    
  </entry>
  
</feed>
